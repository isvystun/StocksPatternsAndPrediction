{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "import yfinance\n",
    "import stock_utils\n",
    "import config\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = stock_utils.fetch_liquid_stocks(min_price=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored = stock_utils.get_ignored_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tickers = list(set(tickers) - set(ignored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total filtered stocks: 189\n",
      "\n",
      "['KMI', 'WEN', 'CLNE', 'SNAP', 'RUN', 'KO', 'SCHW', 'TIGR', 'TPR', 'HBI', 'CVX', 'IPG', 'SLM', 'XOM', 'MTCH', 'JBLU', 'MRNA', 'AAPL', 'HPQ', 'KR', 'PCG', 'AMD', 'MRK', 'IFF', 'ATVI', 'MS', 'SPWR', 'MDT', 'ANGI', 'PSTG', 'MSFT', 'NVAX', 'WFC', 'ATUS', 'FCX', 'NVDA', 'FTI', 'DD', 'APPS', 'RMG', 'COG', 'BA', 'KODK', 'DVAX', 'MPC', 'HPE', 'NEM', 'AMAT', 'C', 'PINS', 'CCL', 'IBM', 'DIS', 'BNGO', 'VZ', 'WKHS', 'BLNK', 'TMUS', 'DVN', 'SRNE', 'EBAY', 'VERU', 'WORK', 'JEF', 'SABR', 'LYFT', 'GT', 'BSX', 'BAC', 'CAH', 'KHC', 'X', 'USB', 'COP', 'SINO', 'SYF', 'PG', 'PM', 'NRZ', 'WMB', 'UNH', 'MO', 'DXC', 'EOG', 'INO', 'SUNW', 'GE', 'ON', 'SPG', 'PLUG', 'AA', 'SQ', 'MOS', 'CUB', 'SAVE', 'NEE', 'OXY', 'ARYA', 'UAA', 'LUV', 'PRTS', 'PFE', 'WMT', 'MGM', 'FTV', 'BCRX', 'DELL', 'CSCO', 'KEY', 'GM', 'DAL', 'CLF', 'SLB', 'F', 'KDP', 'AES', 'MU', 'ZNGA', 'FEYE', 'FHN', 'LEN', 'AVXL', 'DDD', 'MVIS', 'PBF', 'EQT', 'HST', 'LVS', 'INTC', 'JNJ', 'GEVO', 'BBBY', 'WWR', 'CSX', 'ISBC', 'BMY', 'MDLZ', 'PYPL', 'TSLA', 'ORCL', 'MARA', 'GSX', 'TDC', 'TWTR', 'M', 'SBUX', 'NCLH', 'JPM', 'FB', 'SAVA', 'PENN', 'FE', 'ABBV', 'WDC', 'VLO', 'QCOM', 'DBX', 'PEP', 'CVS', 'FOXA', 'APA', 'MAC', 'TJX', 'AFL', 'RIOT', 'AGNC', 'NOV', 'CRM', 'HAL', 'V', 'GME', 'RF', 'NKE', 'HBAN', 'AAL', 'EXC', 'TXN', 'ICLK', 'EPD', 'GILD', 'UBER', 'FCEL', 'NIO', 'T', 'UAL', 'MET', 'CNC', 'CLVS', 'WY']\n"
     ]
    }
   ],
   "source": [
    "print(f'Total filtered stocks: {len(filtered_tickers)}')\n",
    "print('')\n",
    "print(filtered_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async with aiohttp.ClientSession() as session:\n",
    "#     for t in filtered_tickers[:253]:\n",
    "#         data[t] =  await stock_utils.fetch_historical_data_financialmodelingprep(t, config.FINANCIALMODELINGPREP_API, session, save_to_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERIOD = '2y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for t in filtered_tickers:\n",
    "    try:\n",
    "        s = yfinance.Ticker(t)\n",
    "        data[t] =  s.history(period=PERIOD)\n",
    "        data[t].reset_index(inplace=True)\n",
    "        data[t].columns = data[t].columns.str.lower()\n",
    "        data[t] = data[t].iloc[::-1,:].reset_index(drop=True)\n",
    "    except :\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bar import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open price must be between High and Low:\n",
      " High:106.23999786376953 => Open:101.8499984741211 >= Low:101.87010192871094\n",
      "Open price must be between High and Low:\n",
      " High:62.33000183105469 => Open:59.84000015258789 >= Low:59.90999984741211\n"
     ]
    }
   ],
   "source": [
    "patterns_list2 = []\n",
    "for key in data.keys():\n",
    "    if data[key].empty or len(data[key]) < 2:\n",
    "        continue\n",
    "    try:\n",
    "        bar1 = Bar(\n",
    "            data[key].loc[0, 'open'],\n",
    "            data[key].loc[0, 'high'],\n",
    "            data[key].loc[0, 'low'],\n",
    "            data[key].loc[0, 'close']\n",
    "        )\n",
    "        bar2 = Bar(\n",
    "            data[key].loc[1, 'open'],\n",
    "            data[key].loc[1, 'high'],\n",
    "            data[key].loc[1, 'low'],\n",
    "            data[key].loc[1, 'close']\n",
    "        )\n",
    "        if bar1  <= bar2:\n",
    "            patterns_list2.append(key)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open price must be between High and Low:\n",
      " High:106.23999786376953 => Open:101.8499984741211 >= Low:101.87010192871094\n",
      "Open price must be between High and Low:\n",
      " High:62.33000183105469 => Open:59.84000015258789 >= Low:59.90999984741211\n"
     ]
    }
   ],
   "source": [
    "patterns_list = []\n",
    "for key in data.keys():\n",
    "    if data[key].empty or len(data[key]) < 3:\n",
    "        continue\n",
    "    try:\n",
    "        bar1 = Bar(\n",
    "            data[key].loc[0, 'open'],\n",
    "            data[key].loc[0, 'high'],\n",
    "            data[key].loc[0, 'low'],\n",
    "            data[key].loc[0, 'close'],\n",
    "        )\n",
    "        bar2 = Bar(\n",
    "            data[key].loc[1, 'open'],\n",
    "            data[key].loc[1, 'high'],\n",
    "            data[key].loc[1, 'low'],\n",
    "            data[key].loc[1, 'close'],\n",
    "        )\n",
    "        bar3 = Bar(\n",
    "            data[key].loc[2, 'open'],\n",
    "            data[key].loc[2, 'high'],\n",
    "            data[key].loc[2, 'low'],\n",
    "            data[key].loc[2, 'close'],\n",
    "        )\n",
    "        if bar1 <= bar2 <= bar3:\n",
    "            patterns_list.append(key)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SNAP,RUN,SCHW,TIGR,HBI,IPG,MTCH,KR,PCG,MRK,SPWR,MS,ATVI,ANGI,MDT,ATUS,FCX,FTI,APPS,RMG,COG,BA,NEM,C,CCL,PINS,TMUS,DVN,EBAY,SABR,GT,CAH,KHC,X,NRZ,UNH,SUNW,PLUG,AA,UAA,PFE,WMT,MGM,BCRX,CSCO,KEY,CLF,F,ZNGA,LEN,AVXL,EQT,HST,LVS,BBBY,ISBC,TSLA,GSX,TWTR,M,SBUX,NCLH,QCOM,DBX,PEP,CVS,FOXA,MAC,AFL,AGNC,NOV,GME,NKE,HBAN,EXC,TXN,EPD,GILD,CNC'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(set(patterns_list+patterns_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SNAP,RUN,SCHW,TIGR,HBI,IPG,MTCH,KR,PCG,MRK,ATVI,MS,SPWR,MDT,ANGI,ATUS,FCX,FTI,APPS,RMG,COG,BA,NEM,C,PINS,CCL,TMUS,DVN,EBAY,SABR,GT,CAH,KHC,X,NRZ,UNH,SUNW,PLUG,AA,UAA,PFE,WMT,MGM,BCRX,CSCO,KEY,CLF,F,ZNGA,LEN,AVXL,EQT,HST,LVS,BBBY,ISBC,TSLA,GSX,TWTR,M,SBUX,NCLH,QCOM,DBX,PEP,CVS,FOXA,MAC,AFL,AGNC,NOV,GME,NKE,HBAN,EXC,TXN,EPD,GILD,CNC'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(patterns_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open price must be between High and Low:\n",
      " High:106.23999786376953 => Open:101.8499984741211 >= Low:101.87010192871094\n",
      "Open price must be between High and Low:\n",
      " High:62.33000183105469 => Open:59.84000015258789 >= Low:59.90999984741211\n"
     ]
    }
   ],
   "source": [
    "patterns_list3 = []\n",
    "for key in data.keys():\n",
    "    if data[key].empty or len(data[key]) < 3:\n",
    "        continue\n",
    "    try:\n",
    "        bar1 = Bar(\n",
    "            data[key].loc[0, 'open'],\n",
    "            data[key].loc[0, 'high'],\n",
    "            data[key].loc[0, 'low'],\n",
    "            data[key].loc[0, 'close'],\n",
    "        )\n",
    "        bar2 = Bar(\n",
    "            data[key].loc[1, 'open'],\n",
    "            data[key].loc[1, 'high'],\n",
    "            data[key].loc[1, 'low'],\n",
    "            data[key].loc[1, 'close'],\n",
    "        )\n",
    "        bar3 = Bar(\n",
    "            data[key].loc[2, 'open'],\n",
    "            data[key].loc[2, 'high'],\n",
    "            data[key].loc[2, 'low'],\n",
    "            data[key].loc[2, 'close'],\n",
    "        )\n",
    "        if (bar3.range / bar2.range >= 1.7) and (bar2.range / bar1.range) >= 0.95:\n",
    "            patterns_list3.append(key)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MDT,WKHS,SUNW,CSCO,AVXL,BBBY,SAVA,MAC,HBAN,EXC'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(patterns_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open price must be between High and Low:\n",
      " High:106.23999786376953 => Open:101.8499984741211 >= Low:101.87010192871094\n",
      "Open price must be between High and Low:\n",
      " High:62.33000183105469 => Open:59.84000015258789 >= Low:59.90999984741211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'KMI,WEN,CLNE,XOM,MRNA,HPQ,AMD,NVAX,WFC,NVDA,DVAX,MPC,HPE,DIS,BNGO,SRNE,VERU,JEF,COP,SINO,EOG,INO,ON,SQ,MOS,OXY,ARYA,LUV,PRTS,GM,DAL,MU,PBF,GEVO,CSX,PYPL,MARA,PENN,ABBV,VLO,APA,RIOT,V,RF,FCEL,NIO,T,UAL'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns_list4 = []\n",
    "for key in data.keys():\n",
    "    if data[key].empty or len(data[key]) < 3:\n",
    "        continue\n",
    "    try:\n",
    "        bar1 = Bar(\n",
    "            data[key].loc[0, 'open'],\n",
    "            data[key].loc[0, 'high'],\n",
    "            data[key].loc[0, 'low'],\n",
    "            data[key].loc[0, 'close'],\n",
    "        )\n",
    "        bar2 = Bar(\n",
    "            data[key].loc[1, 'open'],\n",
    "            data[key].loc[1, 'high'],\n",
    "            data[key].loc[1, 'low'],\n",
    "            data[key].loc[1, 'close'],\n",
    "        )\n",
    "        if (bar2.range * 1.5 < bar1.range) and ((bar1._close > bar2._high) or (bar1._close < bar2._low)):\n",
    "            patterns_list4.append(key)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "','.join(patterns_list4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_featuring(series_df, prefix):\n",
    "    series_df['per_changed'] =  round((series_df.close - series_df.shift(-1).close)*100 / series_df.shift(-1).close, 2)\n",
    "    series_df['cluster'] = pd.cut(series_df.per_changed, bins=[-99 , -5, -4.5 , -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5,  np.inf], labels=list(range(21))) \n",
    "    #series_df['cluster'] = pd.cut(series_df.per_changed, bins=[-99,-3 ,-0.5, 0.5, 3, np.inf], labels=list(range(5)))\n",
    "    #series_df['cluster'] = pd.cut(series_df.per_changed, bins=[-99, -0.5, 0.5, np.inf], labels=list(range(3)))\n",
    "    dummy_df = pd.get_dummies(series_df['cluster'], prefix=prefix, prefix_sep='_', drop_first=True)\n",
    "    return pd.concat([series_df[['date']], dummy_df], axis=1)\n",
    "    #return dummy_df\n",
    "    \n",
    "\n",
    "def df_featuring_v2(series_df):\n",
    "    series_df['per_changed'] =  round((series_df.close - series_df.shift(-1).close)*100 / series_df.shift(-1).close, 2)\n",
    "    #series_df['cluster'] = pd.cut(series_df.per_changed, bins=[-99,-6, -4, -2, -0.5, 0.5, 2, 4, 6, np.inf], labels=list(range(9)))\n",
    "    #series_df['cluster'] = pd.cut(series_df.per_changed, bins=[-99, -2, -0.5, 0.5, 2, np.inf], labels=list(range(5)))\n",
    "    series_df['cluster'] = pd.cut(series_df.per_changed, bins=[-99, -0.7, 0.7, np.inf], labels=list(range(3)))\n",
    "    series_df['gap'] =  (series_df.open > series_df.shift(-1).high) | (series_df.open < series_df.shift(-1).low)\n",
    "    return series_df[['date', 'open', 'high', 'low', 'close', 'cluster', 'gap']]\n",
    "\n",
    "def model_df_v2(series_df, days=3):\n",
    "    # model columns\n",
    "    c =  []\n",
    "    model_columns = []\n",
    "    for n in range(days,0,-1):\n",
    "        model_columns.extend(['o_'+str(n),\n",
    "                  'h_'+str(n),\n",
    "                  'l_'+str(n),\n",
    "                  'c_'+str(n)])\n",
    "    model_columns.append('o_0')\n",
    "    c.extend(model_columns)\n",
    "\n",
    "    spy_dummy_columns= ['spy_'+str(n) for n in range(1, 21)]\n",
    "    vix_dummy_columns= ['vix_'+str(n) for n in range(1, 21)]\n",
    "    qqq_dummy_columns= ['qqq_'+str(n) for n in range(1, 21)]\n",
    "    dxy_dummy_columns= ['dxy_'+str(n) for n in range(1, 21)]\n",
    "    dummy_columns = spy_dummy_columns + vix_dummy_columns + qqq_dummy_columns + dxy_dummy_columns\n",
    "    c.extend(dummy_columns)\n",
    "    c.append('cluster')\n",
    "    df = pd.DataFrame(columns=c)\n",
    "    for n in range(days,0,-1):\n",
    "        df['o_' + str(n)] = series_df.shift(-n)['open']\n",
    "        df['h_' + str(n)] = series_df.shift(-n)['high']\n",
    "        df['l_' + str(n)] = series_df.shift(-n)['low']\n",
    "        df['c_' + str(n)] = series_df.shift(-n)['close']\n",
    "    df['o_0'] = series_df['open']\n",
    "    df['cluster'] = series_df['cluster']   \n",
    "    df[dummy_columns] = series_df[dummy_columns]\n",
    "    df.dropna(inplace=True)\n",
    "    # opened without gap\n",
    "    df = df[series_df['gap'] == False]\n",
    "\n",
    "    #normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    df[model_columns] = scaler.fit_transform(df[model_columns].T).T\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data(ticker, period='2y'):\n",
    "    res = yfinance.Ticker(ticker)\n",
    "    res =  res.history(period=period)\n",
    "    res.reset_index(inplace=True)\n",
    "    res.columns = res.columns.str.lower()\n",
    "    res = res.iloc[::-1,:].reset_index(drop=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vix_1</th>\n",
       "      <th>vix_2</th>\n",
       "      <th>vix_3</th>\n",
       "      <th>vix_4</th>\n",
       "      <th>vix_5</th>\n",
       "      <th>vix_6</th>\n",
       "      <th>vix_7</th>\n",
       "      <th>vix_8</th>\n",
       "      <th>vix_9</th>\n",
       "      <th>...</th>\n",
       "      <th>vix_11</th>\n",
       "      <th>vix_12</th>\n",
       "      <th>vix_13</th>\n",
       "      <th>vix_14</th>\n",
       "      <th>vix_15</th>\n",
       "      <th>vix_16</th>\n",
       "      <th>vix_17</th>\n",
       "      <th>vix_18</th>\n",
       "      <th>vix_19</th>\n",
       "      <th>vix_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  vix_1  vix_2  vix_3  vix_4  vix_5  vix_6  vix_7  vix_8  vix_9  \\\n",
       "0   2021-02-08      0      0      0      0      0      0      0      0      0   \n",
       "1   2021-02-05      0      1      0      0      0      0      0      0      0   \n",
       "2   2021-02-04      1      0      0      0      0      0      0      0      0   \n",
       "3   2021-02-03      0      0      0      0      0      0      0      0      0   \n",
       "4   2021-02-02      0      0      0      0      0      0      0      0      0   \n",
       "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "498 2019-02-15      0      0      0      0      0      0      0      0      0   \n",
       "499 2019-02-14      0      0      0      0      0      0      0      0      0   \n",
       "500 2019-02-13      0      0      0      0      0      0      0      0      0   \n",
       "501 2019-02-12      0      0      0      1      0      0      0      0      0   \n",
       "502 2019-02-11      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "     ...  vix_11  vix_12  vix_13  vix_14  vix_15  vix_16  vix_17  vix_18  \\\n",
       "0    ...       0       0       1       0       0       0       0       0   \n",
       "1    ...       0       0       0       0       0       0       0       0   \n",
       "2    ...       0       0       0       0       0       0       0       0   \n",
       "3    ...       0       0       0       0       0       0       0       0   \n",
       "4    ...       0       0       0       0       0       0       0       0   \n",
       "..   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "498  ...       0       0       0       0       0       0       0       0   \n",
       "499  ...       0       0       0       0       0       0       1       0   \n",
       "500  ...       0       1       0       0       0       0       0       0   \n",
       "501  ...       0       0       0       0       0       0       0       0   \n",
       "502  ...       0       0       0       0       0       0       0       0   \n",
       "\n",
       "     vix_19  vix_20  \n",
       "0         0       0  \n",
       "1         0       0  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "..      ...     ...  \n",
       "498       0       0  \n",
       "499       0       0  \n",
       "500       0       0  \n",
       "501       0       0  \n",
       "502       0       0  \n",
       "\n",
       "[503 rows x 21 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix = get_ticker_data('^VIX', period=PERIOD)\n",
    "vix_dummy = dummy_featuring(vix, 'vix')\n",
    "vix_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>qqq_1</th>\n",
       "      <th>qqq_2</th>\n",
       "      <th>qqq_3</th>\n",
       "      <th>qqq_4</th>\n",
       "      <th>qqq_5</th>\n",
       "      <th>qqq_6</th>\n",
       "      <th>qqq_7</th>\n",
       "      <th>qqq_8</th>\n",
       "      <th>qqq_9</th>\n",
       "      <th>...</th>\n",
       "      <th>qqq_11</th>\n",
       "      <th>qqq_12</th>\n",
       "      <th>qqq_13</th>\n",
       "      <th>qqq_14</th>\n",
       "      <th>qqq_15</th>\n",
       "      <th>qqq_16</th>\n",
       "      <th>qqq_17</th>\n",
       "      <th>qqq_18</th>\n",
       "      <th>qqq_19</th>\n",
       "      <th>qqq_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  qqq_1  qqq_2  qqq_3  qqq_4  qqq_5  qqq_6  qqq_7  qqq_8  qqq_9  \\\n",
       "0   2021-02-08      0      0      0      0      0      0      0      0      0   \n",
       "1   2021-02-05      0      0      0      0      0      0      0      0      0   \n",
       "2   2021-02-04      0      0      0      0      0      0      0      0      0   \n",
       "3   2021-02-03      0      0      0      0      0      0      0      0      0   \n",
       "4   2021-02-02      0      0      0      0      0      0      0      0      0   \n",
       "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "498 2019-02-15      0      0      0      0      0      0      0      0      0   \n",
       "499 2019-02-14      0      0      0      0      0      0      0      0      0   \n",
       "500 2019-02-13      0      0      0      0      0      0      0      0      0   \n",
       "501 2019-02-12      0      0      0      0      0      0      0      0      0   \n",
       "502 2019-02-11      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "     ...  qqq_11  qqq_12  qqq_13  qqq_14  qqq_15  qqq_16  qqq_17  qqq_18  \\\n",
       "0    ...       1       0       0       0       0       0       0       0   \n",
       "1    ...       0       0       0       0       0       0       0       0   \n",
       "2    ...       0       1       0       0       0       0       0       0   \n",
       "3    ...       0       0       0       0       0       0       0       0   \n",
       "4    ...       0       0       1       0       0       0       0       0   \n",
       "..   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "498  ...       0       0       0       0       0       0       0       0   \n",
       "499  ...       0       0       0       0       0       0       0       0   \n",
       "500  ...       0       0       0       0       0       0       0       0   \n",
       "501  ...       0       1       0       0       0       0       0       0   \n",
       "502  ...       0       0       0       0       0       0       0       0   \n",
       "\n",
       "     qqq_19  qqq_20  \n",
       "0         0       0  \n",
       "1         0       0  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "..      ...     ...  \n",
       "498       0       0  \n",
       "499       0       0  \n",
       "500       0       0  \n",
       "501       0       0  \n",
       "502       0       0  \n",
       "\n",
       "[503 rows x 21 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qqq = get_ticker_data('QQQ', period=PERIOD)\n",
    "qqq_dummy = dummy_featuring(qqq, 'qqq')\n",
    "qqq_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "      <th>stock splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>389.269989</td>\n",
       "      <td>390.559998</td>\n",
       "      <td>388.350006</td>\n",
       "      <td>390.510010</td>\n",
       "      <td>38463195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>388.200012</td>\n",
       "      <td>388.470001</td>\n",
       "      <td>386.140015</td>\n",
       "      <td>387.709991</td>\n",
       "      <td>48620300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>382.959991</td>\n",
       "      <td>386.239990</td>\n",
       "      <td>381.970001</td>\n",
       "      <td>386.190002</td>\n",
       "      <td>47142600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>382.440002</td>\n",
       "      <td>383.700012</td>\n",
       "      <td>380.480011</td>\n",
       "      <td>381.850006</td>\n",
       "      <td>52427100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>379.649994</td>\n",
       "      <td>383.220001</td>\n",
       "      <td>376.320007</td>\n",
       "      <td>381.549988</td>\n",
       "      <td>64450700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>266.251908</td>\n",
       "      <td>267.263521</td>\n",
       "      <td>266.030339</td>\n",
       "      <td>267.224976</td>\n",
       "      <td>97088700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>263.766330</td>\n",
       "      <td>265.558315</td>\n",
       "      <td>262.889611</td>\n",
       "      <td>264.344391</td>\n",
       "      <td>83234400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>264.970552</td>\n",
       "      <td>265.837628</td>\n",
       "      <td>264.517741</td>\n",
       "      <td>264.932007</td>\n",
       "      <td>65277200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>262.456070</td>\n",
       "      <td>264.479237</td>\n",
       "      <td>262.378979</td>\n",
       "      <td>264.074615</td>\n",
       "      <td>72270200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>261.280696</td>\n",
       "      <td>261.560068</td>\n",
       "      <td>260.153476</td>\n",
       "      <td>260.721893</td>\n",
       "      <td>68021400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        open        high         low       close    volume  \\\n",
       "0   2021-02-08  389.269989  390.559998  388.350006  390.510010  38463195   \n",
       "1   2021-02-05  388.200012  388.470001  386.140015  387.709991  48620300   \n",
       "2   2021-02-04  382.959991  386.239990  381.970001  386.190002  47142600   \n",
       "3   2021-02-03  382.440002  383.700012  380.480011  381.850006  52427100   \n",
       "4   2021-02-02  379.649994  383.220001  376.320007  381.549988  64450700   \n",
       "..         ...         ...         ...         ...         ...       ...   \n",
       "498 2019-02-15  266.251908  267.263521  266.030339  267.224976  97088700   \n",
       "499 2019-02-14  263.766330  265.558315  262.889611  264.344391  83234400   \n",
       "500 2019-02-13  264.970552  265.837628  264.517741  264.932007  65277200   \n",
       "501 2019-02-12  262.456070  264.479237  262.378979  264.074615  72270200   \n",
       "502 2019-02-11  261.280696  261.560068  260.153476  260.721893  68021400   \n",
       "\n",
       "     dividends  stock splits  \n",
       "0          0.0             0  \n",
       "1          0.0             0  \n",
       "2          0.0             0  \n",
       "3          0.0             0  \n",
       "4          0.0             0  \n",
       "..         ...           ...  \n",
       "498        0.0             0  \n",
       "499        0.0             0  \n",
       "500        0.0             0  \n",
       "501        0.0             0  \n",
       "502        0.0             0  \n",
       "\n",
       "[503 rows x 8 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy = get_ticker_data('SPY', period=PERIOD)\n",
    "spy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dxy_1</th>\n",
       "      <th>dxy_2</th>\n",
       "      <th>dxy_3</th>\n",
       "      <th>dxy_4</th>\n",
       "      <th>dxy_5</th>\n",
       "      <th>dxy_6</th>\n",
       "      <th>dxy_7</th>\n",
       "      <th>dxy_8</th>\n",
       "      <th>dxy_9</th>\n",
       "      <th>...</th>\n",
       "      <th>dxy_11</th>\n",
       "      <th>dxy_12</th>\n",
       "      <th>dxy_13</th>\n",
       "      <th>dxy_14</th>\n",
       "      <th>dxy_15</th>\n",
       "      <th>dxy_16</th>\n",
       "      <th>dxy_17</th>\n",
       "      <th>dxy_18</th>\n",
       "      <th>dxy_19</th>\n",
       "      <th>dxy_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  dxy_1  dxy_2  dxy_3  dxy_4  dxy_5  dxy_6  dxy_7  dxy_8  dxy_9  \\\n",
       "0   2021-02-08      0      0      0      0      0      0      0      0      0   \n",
       "1   2021-02-05      0      0      0      0      0      0      0      0      1   \n",
       "2   2021-02-04      0      0      0      0      0      0      0      0      0   \n",
       "3   2021-02-03      0      0      0      0      0      0      0      0      0   \n",
       "4   2021-02-02      0      0      0      0      0      0      0      0      0   \n",
       "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "494 2019-02-14      0      0      0      0      0      0      0      0      0   \n",
       "495 2019-02-13      0      0      0      0      0      0      0      0      0   \n",
       "496 2019-02-12      0      0      0      0      0      0      0      0      0   \n",
       "497 2019-02-11      0      0      0      0      0      0      0      0      0   \n",
       "498 2019-02-08      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "     ...  dxy_11  dxy_12  dxy_13  dxy_14  dxy_15  dxy_16  dxy_17  dxy_18  \\\n",
       "0    ...       0       0       0       0       0       0       0       0   \n",
       "1    ...       0       0       0       0       0       0       0       0   \n",
       "2    ...       0       0       0       0       0       0       0       0   \n",
       "3    ...       0       0       0       0       0       0       0       0   \n",
       "4    ...       0       0       0       0       0       0       0       0   \n",
       "..   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "494  ...       0       0       0       0       0       0       0       0   \n",
       "495  ...       0       0       0       0       0       0       0       0   \n",
       "496  ...       0       0       0       0       0       0       0       0   \n",
       "497  ...       0       0       0       0       0       0       0       0   \n",
       "498  ...       0       0       0       0       0       0       0       0   \n",
       "\n",
       "     dxy_19  dxy_20  \n",
       "0         0       0  \n",
       "1         0       0  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "..      ...     ...  \n",
       "494       0       0  \n",
       "495       0       0  \n",
       "496       0       0  \n",
       "497       0       0  \n",
       "498       0       0  \n",
       "\n",
       "[499 rows x 21 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dxy = get_ticker_data('DX-Y.NYB', period=PERIOD)\n",
    "dxy_dummy = dummy_featuring(dxy, 'dxy')\n",
    "dxy_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>spy_1</th>\n",
       "      <th>spy_2</th>\n",
       "      <th>spy_3</th>\n",
       "      <th>spy_4</th>\n",
       "      <th>spy_5</th>\n",
       "      <th>spy_6</th>\n",
       "      <th>spy_7</th>\n",
       "      <th>spy_8</th>\n",
       "      <th>spy_9</th>\n",
       "      <th>...</th>\n",
       "      <th>dxy_11</th>\n",
       "      <th>dxy_12</th>\n",
       "      <th>dxy_13</th>\n",
       "      <th>dxy_14</th>\n",
       "      <th>dxy_15</th>\n",
       "      <th>dxy_16</th>\n",
       "      <th>dxy_17</th>\n",
       "      <th>dxy_18</th>\n",
       "      <th>dxy_19</th>\n",
       "      <th>dxy_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  spy_1  spy_2  spy_3  spy_4  spy_5  spy_6  spy_7  spy_8  spy_9  \\\n",
       "0   2021-02-08      0      0      0      0      0      0      0      0      0   \n",
       "1   2021-02-05      0      0      0      0      0      0      0      0      0   \n",
       "2   2021-02-04      0      0      0      0      0      0      0      0      0   \n",
       "3   2021-02-03      0      0      0      0      0      0      0      0      0   \n",
       "4   2021-02-02      0      0      0      0      0      0      0      0      0   \n",
       "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "498 2019-02-15      0      0      0      0      0      0      0      0      0   \n",
       "499 2019-02-14      0      0      0      0      0      0      0      0      0   \n",
       "500 2019-02-13      0      0      0      0      0      0      0      0      0   \n",
       "501 2019-02-12      0      0      0      0      0      0      0      0      0   \n",
       "502 2019-02-11      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "     ...  dxy_11  dxy_12  dxy_13  dxy_14  dxy_15  dxy_16  dxy_17  dxy_18  \\\n",
       "0    ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1    ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2    ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3    ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4    ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "..   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "498  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "499  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "500  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "501  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "502  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     dxy_19  dxy_20  \n",
       "0       0.0     0.0  \n",
       "1       0.0     0.0  \n",
       "2       0.0     0.0  \n",
       "3       0.0     0.0  \n",
       "4       0.0     0.0  \n",
       "..      ...     ...  \n",
       "498     0.0     0.0  \n",
       "499     0.0     0.0  \n",
       "500     0.0     0.0  \n",
       "501     0.0     0.0  \n",
       "502     0.0     0.0  \n",
       "\n",
       "[503 rows x 81 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_dummy = dummy_featuring(spy, 'spy')\n",
    "spy_dummy = spy_dummy.merge(vix_dummy, on='date', how='left')\n",
    "spy_dummy = spy_dummy.merge(qqq_dummy, on='date', how='left')\n",
    "spy_dummy = spy_dummy.merge(dxy_dummy, on='date', how='left')\n",
    "spy_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_dfs = []\n",
    "for key in data.keys():\n",
    "    if data[key].empty:\n",
    "        continue\n",
    "    f_data = df_featuring_v2(data[key])\n",
    "    merge_data = f_data.merge(spy_dummy, on='date', how='left')\n",
    "    m = model_df_v2(merge_data, days=4)\n",
    "    featured_dfs.append(m)\n",
    "m = pd.concat(featured_dfs, ignore_index=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o_4</th>\n",
       "      <th>h_4</th>\n",
       "      <th>l_4</th>\n",
       "      <th>c_4</th>\n",
       "      <th>o_3</th>\n",
       "      <th>h_3</th>\n",
       "      <th>l_3</th>\n",
       "      <th>c_3</th>\n",
       "      <th>o_2</th>\n",
       "      <th>h_2</th>\n",
       "      <th>...</th>\n",
       "      <th>dxy_12</th>\n",
       "      <th>dxy_13</th>\n",
       "      <th>dxy_14</th>\n",
       "      <th>dxy_15</th>\n",
       "      <th>dxy_16</th>\n",
       "      <th>dxy_17</th>\n",
       "      <th>dxy_18</th>\n",
       "      <th>dxy_19</th>\n",
       "      <th>dxy_20</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.234374</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.906249</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093751</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.199999</td>\n",
       "      <td>0.360001</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.920741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.554165</td>\n",
       "      <td>0.682961</td>\n",
       "      <td>0.575019</td>\n",
       "      <td>0.756604</td>\n",
       "      <td>0.262290</td>\n",
       "      <td>0.332906</td>\n",
       "      <td>0.423698</td>\n",
       "      <td>0.474139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.846697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.731719</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.754714</td>\n",
       "      <td>0.394451</td>\n",
       "      <td>0.425112</td>\n",
       "      <td>0.509429</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.970297</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.534654</td>\n",
       "      <td>0.653466</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64273</th>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.375001</td>\n",
       "      <td>0.097221</td>\n",
       "      <td>0.263890</td>\n",
       "      <td>0.180555</td>\n",
       "      <td>0.569446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>0.402775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64274</th>\n",
       "      <td>0.385966</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.570176</td>\n",
       "      <td>0.605265</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.535089</td>\n",
       "      <td>0.482457</td>\n",
       "      <td>0.728072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64275</th>\n",
       "      <td>0.518073</td>\n",
       "      <td>0.879517</td>\n",
       "      <td>0.265060</td>\n",
       "      <td>0.554216</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.855419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590360</td>\n",
       "      <td>0.783132</td>\n",
       "      <td>0.831326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64276</th>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.945206</td>\n",
       "      <td>0.273972</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.589042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.972601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64277</th>\n",
       "      <td>0.793816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>0.711341</td>\n",
       "      <td>0.206185</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.443300</td>\n",
       "      <td>0.752578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64278 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            o_4       h_4       l_4       c_4       o_3       h_3       l_3  \\\n",
       "0      0.656250  0.734375  0.234374  0.421875  0.906249  0.921875  0.000000   \n",
       "1      0.760000  1.000000  0.346667  0.440000  0.560000  0.626667  0.199999   \n",
       "2      0.920741  1.000000  0.554165  0.682961  0.575019  0.756604  0.262290   \n",
       "3      0.846697  1.000000  0.639737  0.731719  0.639737  0.754714  0.394451   \n",
       "4      0.683168  0.970297  0.455446  0.693069  0.801980  1.000000  0.534654   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "64273  0.319444  0.375001  0.097221  0.263890  0.180555  0.569446  0.000000   \n",
       "64274  0.385966  0.622807  0.000000  0.429825  0.570176  0.605265  0.429825   \n",
       "64275  0.518073  0.879517  0.265060  0.554216  0.530120  0.855419  0.000000   \n",
       "64276  0.767123  0.945206  0.273972  0.547945  0.589042  1.000000  0.301370   \n",
       "64277  0.793816  1.000000  0.309278  0.484536  0.577320  0.711341  0.206185   \n",
       "\n",
       "            c_3       o_2       h_2  ...  dxy_12  dxy_13  dxy_14  dxy_15  \\\n",
       "0      0.093751  0.140625  0.859375  ...     0.0     0.0     0.0     0.0   \n",
       "1      0.360001  0.773333  0.786667  ...     0.0     0.0     0.0     0.0   \n",
       "2      0.332906  0.423698  0.474139  ...     0.0     0.0     0.0     0.0   \n",
       "3      0.425112  0.509429  0.570751  ...     0.0     0.0     0.0     0.0   \n",
       "4      0.653466  0.534653  0.683168  ...     0.0     0.0     0.0     0.0   \n",
       "...         ...       ...       ...  ...     ...     ...     ...     ...   \n",
       "64273  0.333334  0.402775  1.000000  ...     0.0     0.0     0.0     0.0   \n",
       "64274  0.535089  0.482457  0.728072  ...     0.0     0.0     0.0     0.0   \n",
       "64275  0.590360  0.783132  0.831326  ...     0.0     0.0     0.0     0.0   \n",
       "64276  0.630137  0.602740  0.972601  ...     0.0     0.0     0.0     0.0   \n",
       "64277  0.412371  0.443300  0.752578  ...     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       dxy_16  dxy_17  dxy_18  dxy_19  dxy_20  cluster  \n",
       "0         0.0     0.0     0.0     0.0     0.0        2  \n",
       "1         0.0     0.0     0.0     0.0     0.0        0  \n",
       "2         0.0     0.0     0.0     0.0     0.0        2  \n",
       "3         0.0     0.0     0.0     0.0     0.0        1  \n",
       "4         0.0     0.0     0.0     0.0     0.0        0  \n",
       "...       ...     ...     ...     ...     ...      ...  \n",
       "64273     0.0     0.0     0.0     0.0     0.0        2  \n",
       "64274     0.0     0.0     0.0     0.0     0.0        1  \n",
       "64275     0.0     0.0     0.0     0.0     0.0        2  \n",
       "64276     0.0     0.0     0.0     0.0     0.0        1  \n",
       "64277     0.0     0.0     0.0     0.0     0.0        1  \n",
       "\n",
       "[64278 rows x 98 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>o_3</th>\n",
       "      <th>h_3</th>\n",
       "      <th>l_3</th>\n",
       "      <th>c_3</th>\n",
       "      <th>o_2</th>\n",
       "      <th>h_2</th>\n",
       "      <th>l_2</th>\n",
       "      <th>c_2</th>\n",
       "      <th>o_1</th>\n",
       "      <th>h_1</th>\n",
       "      <th>l_1</th>\n",
       "      <th>c_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.294521</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191780</td>\n",
       "      <td>0.527398</td>\n",
       "      <td>0.527398</td>\n",
       "      <td>0.883562</td>\n",
       "      <td>0.171233</td>\n",
       "      <td>0.527398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.107955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.017046</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.767046</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.176136</td>\n",
       "      <td>0.454546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.494667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054667</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.058667</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.438667</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.494667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.182238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149942</td>\n",
       "      <td>0.154556</td>\n",
       "      <td>0.538639</td>\n",
       "      <td>0.146482</td>\n",
       "      <td>0.514418</td>\n",
       "      <td>0.498270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486736</td>\n",
       "      <td>0.562861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63898</th>\n",
       "      <td>0.945056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692305</td>\n",
       "      <td>0.659339</td>\n",
       "      <td>0.934064</td>\n",
       "      <td>0.296704</td>\n",
       "      <td>0.648352</td>\n",
       "      <td>0.472528</td>\n",
       "      <td>0.857142</td>\n",
       "      <td>0.230768</td>\n",
       "      <td>0.384614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63899</th>\n",
       "      <td>0.021979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>0.615382</td>\n",
       "      <td>0.945056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692305</td>\n",
       "      <td>0.659339</td>\n",
       "      <td>0.934064</td>\n",
       "      <td>0.296704</td>\n",
       "      <td>0.648352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63900</th>\n",
       "      <td>0.086067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.758197</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.614753</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.758197</td>\n",
       "      <td>0.385247</td>\n",
       "      <td>0.643442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63901</th>\n",
       "      <td>0.577868</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.389344</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.086067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.758197</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.614753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63902</th>\n",
       "      <td>0.627050</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.426229</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.577868</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.389344</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.086067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63903 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            o_3       h_3       l_3       c_3       o_2       h_2       l_2  \\\n",
       "0      0.294521  0.739726  0.000000  0.719178  0.904110  1.000000  0.191780   \n",
       "1      0.107955  1.000000  0.000000  0.090909  0.261364  0.630682  0.017046   \n",
       "2      0.420000  1.000000  0.406667  0.494667  0.466667  0.512000  0.000000   \n",
       "3      0.022667  0.466667  0.013333  0.438667  0.420000  1.000000  0.406667   \n",
       "4      0.019608  0.182238  0.000000  0.149942  0.154556  0.538639  0.146482   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "63898  0.945056  1.000000  0.000000  0.692305  0.659339  0.934064  0.296704   \n",
       "63899  0.021979  1.000000  0.021979  0.615382  0.945056  1.000000  0.000000   \n",
       "63900  0.086067  1.000000  0.000000  0.442623  0.393443  0.758197  0.393443   \n",
       "63901  0.577868  0.696721  0.389344  0.500000  0.086067  1.000000  0.000000   \n",
       "63902  0.627050  0.803279  0.426229  0.803279  0.577868  0.696721  0.389344   \n",
       "\n",
       "            c_2       o_1       h_1       l_1       c_1  \n",
       "0      0.527398  0.527398  0.883562  0.171233  0.527398  \n",
       "1      0.613636  0.767046  0.846591  0.176136  0.454546  \n",
       "2      0.054667  0.084000  0.293333  0.058667  0.080000  \n",
       "3      0.494667  0.466667  0.512000  0.000000  0.054667  \n",
       "4      0.514418  0.498270  1.000000  0.486736  0.562861  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "63898  0.648352  0.472528  0.857142  0.230768  0.384614  \n",
       "63899  0.692305  0.659339  0.934064  0.296704  0.648352  \n",
       "63900  0.614753  0.737705  0.758197  0.385247  0.643442  \n",
       "63901  0.442623  0.393443  0.758197  0.393443  0.614753  \n",
       "63902  0.500000  0.086067  1.000000  0.000000  0.442623  \n",
       "\n",
       "[63903 rows x 12 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_data = m[['o_3', 'h_3', 'l_3', 'c_3', 'o_2', 'h_2', 'l_2', 'c_2', 'o_1', 'h_1','l_1', 'c_1']]\n",
    "kmeans_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = model_df_v2(dfs, days=3)\n",
    "#m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(m.drop(['cluster'], axis=1), m.cluster, stratify=m.cluster, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34583471622967143"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train == 0]) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30565466312645206"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train == 1]) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34851062064387656"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train == 2]) / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsc = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                  param_grid={\n",
    "                      'max_depth' : range(3, 10),\n",
    "                      'n_estimators' : (9, 50, 100, 500, 1000, 2000)\n",
    "                  }, \n",
    "                  cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-52f8f704cb25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_results = gsc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_model = grid_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=9, n_estimators=10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49573647345447164"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize(x):\n",
    "    if x < 1:\n",
    "        return 0\n",
    "    elif x > 1:\n",
    "        return 2\n",
    "    else :\n",
    "        return 1\n",
    "    \n",
    "gfunc = np.vectorize(generalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000263476840385"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gfunc(y_pred), gfunc(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.92877518e-04, 3.57142492e-02, 0.00000000e+00, 3.03571544e-02,\n",
       "       8.92877518e-04, 3.57142492e-02, 0.00000000e+00, 3.03571544e-02,\n",
       "       9.74107063e-01, 1.00000000e+00, 9.64285580e-01, 9.82142790e-01,\n",
       "       9.74107063e-01])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class DeepModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.deep_model = Sequential()\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        init_kernel = TruncatedNormal(mean=0, stddev=0.05, seed=1234)\n",
    "        init_bias = Constant(value=1e-3)\n",
    "        \n",
    "\n",
    "        es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "        input_dim = X.shape[1]\n",
    "        hidden_units = int(input_dim / 2)\n",
    "        self.deep_model.add(Dense(hidden_units, input_dim=input_dim, activation='relu', kernel_initializer=init_kernel, bias_initializer=init_bias))\n",
    "        #deep_model.add(Dropout(0.5))\n",
    "        self.deep_model.add(Dense(hidden_units, activation='relu', kernel_initializer=init_kernel, bias_initializer=init_bias))\n",
    "        #deep_model.add(Dense(35, activation='relu', kernel_initializer=init_kernel, bias_initializer=init_bias))\n",
    "        # deep_model.add(Dense(32, activation='relu', kernel_initializer=init_kernel, bias_initializer=init_bias))\n",
    "        # deep_model.add(Dropout(0.4))\n",
    "        self.deep_model.add(Dense(3, activation='softmax', kernel_initializer=init_kernel, bias_initializer=init_bias))\n",
    "        self.deep_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self.deep_model.fit(X, y, epochs=2000, batch_size=32, validation_split=0.2, callbacks=[es_callback])#, validation_data=(X_val, y_val))\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        return self.deep_model.predict(X)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        for res in self.deep_model.predict(X_test):\n",
    "            pred.append(np.argmax(res))\n",
    "        return np.array(pred)\n",
    "    \n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return dict()\n",
    "    \n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential SELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 593us/step - loss: 0.7627 - accuracy: 0.6758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7627151012420654, 0.6757826805114746]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clus = 0\n",
    "deep_model.evaluate(X_test[y_test ==clus], y_test[y_test ==clus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential BUY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 567us/step - loss: 1.0160 - accuracy: 0.5322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0160470008850098, 0.5322263836860657]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clus = 2\n",
    "deep_model.evaluate(X_test[y_test ==clus], y_test[y_test ==clus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    6178\n",
       "0    6093\n",
       "1    5864\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5348221670802316"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "accuracy_score(y_test,  pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 01_23_21.model\\assets\n"
     ]
    }
   ],
   "source": [
    "deep_model.save('01_23_21.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('12_23_20.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "up, down = [], []\n",
    "for key in data.keys():\n",
    "    stock = data[key].iloc[:4]\n",
    "    df = df_featuring_v2(stock).merge(spy_dummy, on='date', how='left')\n",
    "    try:\n",
    "        mt = model_df_v2(df)\n",
    "    except:\n",
    "        continue\n",
    "    pred = loaded_model.predict(mt.drop(['cluster'], axis=1))\n",
    "    signal = np.argmax(pred)\n",
    "    if signal == 0:\n",
    "        down.append((key, pred[0][signal]))\n",
    "    elif signal == 2:\n",
    "        up.append((key, pred[0][signal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DIS', 0.5602764),\n",
       " ('MARA', 0.50385004),\n",
       " ('RIOT', 0.4739845),\n",
       " ('JNJ', 0.41651472),\n",
       " ('WMT', 0.4164169),\n",
       " ('PBCT', 0.40450177),\n",
       " ('POLA', 0.37074807),\n",
       " ('RF', 0.34795973)]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up.sort(key= lambda s : s[1], reverse=True)\n",
    "up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INTC', 0.8266818),\n",
       " ('MGM', 0.7462077),\n",
       " ('FUV', 0.7262829),\n",
       " ('WDC', 0.72622013),\n",
       " ('FANG', 0.71726835),\n",
       " ('TAL', 0.6970729),\n",
       " ('HPQ', 0.6706808),\n",
       " ('CSCO', 0.6659724),\n",
       " ('LUV', 0.66370827),\n",
       " ('TIGR', 0.65436524),\n",
       " ('AAL', 0.64604807),\n",
       " ('NVDA', 0.64337885),\n",
       " ('FIS', 0.63136345),\n",
       " ('SUNW', 0.6282672),\n",
       " ('JNPR', 0.61720806),\n",
       " ('BBBY', 0.60545313),\n",
       " ('AAPL', 0.6053156),\n",
       " ('DVN', 0.60336214),\n",
       " ('SPWR', 0.60221076),\n",
       " ('COG', 0.5951812),\n",
       " ('JCI', 0.58229613),\n",
       " ('DDD', 0.5822772),\n",
       " ('DBX', 0.58187324),\n",
       " ('VUZI', 0.5808423),\n",
       " ('SNAP', 0.58016646),\n",
       " ('FEYE', 0.5798619),\n",
       " ('FSLY', 0.5753547),\n",
       " ('UAL', 0.57488525),\n",
       " ('COF', 0.5678569),\n",
       " ('ORCL', 0.56497693),\n",
       " ('CLNE', 0.56293476),\n",
       " ('LVS', 0.56232405),\n",
       " ('GPS', 0.5557153),\n",
       " ('D', 0.5523694),\n",
       " ('NFLX', 0.5519825),\n",
       " ('WY', 0.55074865),\n",
       " ('RUN', 0.55057204),\n",
       " ('MRNA', 0.54882926),\n",
       " ('PFE', 0.54881394),\n",
       " ('KIM', 0.54834497),\n",
       " ('CVS', 0.5342834),\n",
       " ('CHNG', 0.5338598),\n",
       " ('EXC', 0.5314146),\n",
       " ('KHC', 0.52155036),\n",
       " ('AGNC', 0.5179788),\n",
       " ('RMG', 0.5147651),\n",
       " ('ZNGA', 0.511358),\n",
       " ('WBA', 0.5100903),\n",
       " ('FB', 0.50751716),\n",
       " ('MO', 0.5038323),\n",
       " ('F', 0.49295717),\n",
       " ('BSX', 0.49213776),\n",
       " ('PCG', 0.49186367),\n",
       " ('GSX', 0.49075335),\n",
       " ('PYPL', 0.48576647),\n",
       " ('QCOM', 0.48510778),\n",
       " ('TDOC', 0.4821684),\n",
       " ('BK', 0.47895405),\n",
       " ('SQ', 0.47877505),\n",
       " ('TWTR', 0.4737512),\n",
       " ('MU', 0.47370026),\n",
       " ('MIK', 0.47134843),\n",
       " ('PLUG', 0.46903098),\n",
       " ('KO', 0.46870095),\n",
       " ('FOXA', 0.46844366),\n",
       " ('WKHS', 0.4683744),\n",
       " ('PHM', 0.46811754),\n",
       " ('OSTK', 0.46514705),\n",
       " ('USB', 0.46049383),\n",
       " ('FCEL', 0.4523503),\n",
       " ('HD', 0.45228443),\n",
       " ('VZ', 0.45042408),\n",
       " ('GIS', 0.45030704),\n",
       " ('T', 0.4488083),\n",
       " ('GRTS', 0.44848981),\n",
       " ('PINS', 0.4457801),\n",
       " ('BLNK', 0.4430388),\n",
       " ('LLY', 0.44173673),\n",
       " ('MDLZ', 0.4412089),\n",
       " ('CL', 0.4324136),\n",
       " ('BYND', 0.4248956),\n",
       " ('PEP', 0.41604537),\n",
       " ('GEVO', 0.41189268),\n",
       " ('GME', 0.40937278),\n",
       " ('FPRX', 0.4030337),\n",
       " ('AMRS', 0.40094993),\n",
       " ('SFIX', 0.37801814),\n",
       " ('PG', 0.37398478),\n",
       " ('NEE', 0.3729247),\n",
       " ('NUAN', 0.3702393)]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down.sort(key= lambda s : s[1], reverse=True)\n",
    "down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SRNE',\n",
       " 'WFC',\n",
       " 'GNPX',\n",
       " 'KMI',\n",
       " 'JBLU',\n",
       " 'MDLZ',\n",
       " 'AES',\n",
       " 'PG',\n",
       " 'WMB',\n",
       " 'FCX',\n",
       " 'V',\n",
       " 'DVN',\n",
       " 'M',\n",
       " 'RF',\n",
       " 'AFL',\n",
       " 'KOS',\n",
       " 'USB',\n",
       " 'PFE',\n",
       " 'AMAT',\n",
       " 'JWN',\n",
       " 'NOV',\n",
       " 'HBAN',\n",
       " 'MRO',\n",
       " 'FANG',\n",
       " 'CNP',\n",
       " 'C',\n",
       " 'DAL',\n",
       " 'EBAY',\n",
       " 'GM',\n",
       " 'EVRG',\n",
       " 'TRVN',\n",
       " 'CVX',\n",
       " 'SM',\n",
       " 'NLY',\n",
       " 'CCL',\n",
       " 'GLW',\n",
       " 'NEE',\n",
       " 'SCHW',\n",
       " 'COP',\n",
       " 'PPL',\n",
       " 'APA',\n",
       " 'NRZ',\n",
       " 'BAC',\n",
       " 'TWTR',\n",
       " 'HAL',\n",
       " 'CSX',\n",
       " 'OXY',\n",
       " 'XOM',\n",
       " 'COTY',\n",
       " 'PSTG',\n",
       " 'PAGP',\n",
       " 'GE',\n",
       " 'PBF',\n",
       " 'X',\n",
       " 'BSX',\n",
       " 'SLB',\n",
       " 'HPE',\n",
       " 'MPC',\n",
       " 'AEO',\n",
       " 'HL',\n",
       " 'BE',\n",
       " 'AM',\n",
       " 'KO',\n",
       " 'F',\n",
       " 'VZ',\n",
       " 'PRTY',\n",
       " 'SPWR',\n",
       " 'AR',\n",
       " 'CVS',\n",
       " 'CNK',\n",
       " 'RUN',\n",
       " 'JCI',\n",
       " 'MO',\n",
       " 'RAD',\n",
       " 'SIRI',\n",
       " 'MFA',\n",
       " 'TPR',\n",
       " 'HBI',\n",
       " 'OPK',\n",
       " 'LUV',\n",
       " 'BBBY',\n",
       " 'BA',\n",
       " 'JPM',\n",
       " 'QEP',\n",
       " 'WORK',\n",
       " 'CPE',\n",
       " 'MGM',\n",
       " 'NYMT',\n",
       " 'AQMS',\n",
       " 'CLF',\n",
       " 'PAA',\n",
       " 'LYFT',\n",
       " 'MRK',\n",
       " 'AAPL',\n",
       " 'IDEX',\n",
       " 'JNJ')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*up))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb.fit(X_train, y_train, verbose=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(missing=None, seed=1234, objective='multi:softmax', num_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.05710\tvalidation_0-merror:0.49795\n",
      "[1]\tvalidation_0-mlogloss:1.03269\tvalidation_0-merror:0.49890\n",
      "[2]\tvalidation_0-mlogloss:1.01679\tvalidation_0-merror:0.49549\n",
      "[3]\tvalidation_0-mlogloss:1.00689\tvalidation_0-merror:0.49026\n",
      "[4]\tvalidation_0-mlogloss:1.00008\tvalidation_0-merror:0.49001\n",
      "[5]\tvalidation_0-mlogloss:0.99461\tvalidation_0-merror:0.48679\n",
      "[6]\tvalidation_0-mlogloss:0.99015\tvalidation_0-merror:0.48503\n",
      "[7]\tvalidation_0-mlogloss:0.98605\tvalidation_0-merror:0.48219\n",
      "[8]\tvalidation_0-mlogloss:0.98296\tvalidation_0-merror:0.48194\n",
      "[9]\tvalidation_0-mlogloss:0.97963\tvalidation_0-merror:0.47999\n",
      "[10]\tvalidation_0-mlogloss:0.97677\tvalidation_0-merror:0.47866\n",
      "[11]\tvalidation_0-mlogloss:0.97449\tvalidation_0-merror:0.47955\n",
      "[12]\tvalidation_0-mlogloss:0.97221\tvalidation_0-merror:0.47822\n",
      "[13]\tvalidation_0-mlogloss:0.97094\tvalidation_0-merror:0.47671\n",
      "[14]\tvalidation_0-mlogloss:0.96953\tvalidation_0-merror:0.47753\n",
      "[15]\tvalidation_0-mlogloss:0.96776\tvalidation_0-merror:0.47646\n",
      "[16]\tvalidation_0-mlogloss:0.96639\tvalidation_0-merror:0.47576\n",
      "[17]\tvalidation_0-mlogloss:0.96450\tvalidation_0-merror:0.47450\n",
      "[18]\tvalidation_0-mlogloss:0.96335\tvalidation_0-merror:0.47299\n",
      "[19]\tvalidation_0-mlogloss:0.96175\tvalidation_0-merror:0.47375\n",
      "[20]\tvalidation_0-mlogloss:0.96104\tvalidation_0-merror:0.47192\n",
      "[21]\tvalidation_0-mlogloss:0.96046\tvalidation_0-merror:0.47186\n",
      "[22]\tvalidation_0-mlogloss:0.95896\tvalidation_0-merror:0.47104\n",
      "[23]\tvalidation_0-mlogloss:0.95827\tvalidation_0-merror:0.47034\n",
      "[24]\tvalidation_0-mlogloss:0.95783\tvalidation_0-merror:0.46852\n",
      "[25]\tvalidation_0-mlogloss:0.95727\tvalidation_0-merror:0.46845\n",
      "[26]\tvalidation_0-mlogloss:0.95705\tvalidation_0-merror:0.46826\n",
      "[27]\tvalidation_0-mlogloss:0.95676\tvalidation_0-merror:0.46788\n",
      "[28]\tvalidation_0-mlogloss:0.95644\tvalidation_0-merror:0.46719\n",
      "[29]\tvalidation_0-mlogloss:0.95622\tvalidation_0-merror:0.46744\n",
      "[30]\tvalidation_0-mlogloss:0.95594\tvalidation_0-merror:0.46801\n",
      "[31]\tvalidation_0-mlogloss:0.95540\tvalidation_0-merror:0.46927\n",
      "[32]\tvalidation_0-mlogloss:0.95540\tvalidation_0-merror:0.46908\n",
      "[33]\tvalidation_0-mlogloss:0.95500\tvalidation_0-merror:0.46770\n",
      "[34]\tvalidation_0-mlogloss:0.95451\tvalidation_0-merror:0.46612\n",
      "[35]\tvalidation_0-mlogloss:0.95442\tvalidation_0-merror:0.46637\n",
      "[36]\tvalidation_0-mlogloss:0.95445\tvalidation_0-merror:0.46625\n",
      "[37]\tvalidation_0-mlogloss:0.95440\tvalidation_0-merror:0.46707\n",
      "[38]\tvalidation_0-mlogloss:0.95453\tvalidation_0-merror:0.46719\n",
      "[39]\tvalidation_0-mlogloss:0.95430\tvalidation_0-merror:0.46807\n",
      "[40]\tvalidation_0-mlogloss:0.95422\tvalidation_0-merror:0.46770\n",
      "[41]\tvalidation_0-mlogloss:0.95423\tvalidation_0-merror:0.46770\n",
      "[42]\tvalidation_0-mlogloss:0.95433\tvalidation_0-merror:0.46725\n",
      "[43]\tvalidation_0-mlogloss:0.95423\tvalidation_0-merror:0.46675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_class=3, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=1234, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=1234, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric=['mlogloss', 'merror'], eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignored_filter = y_test != 1\n",
    "#X_test_filtered = X_test[ignored_filter]\n",
    "#y_test_filtered = y_test[ignored_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2549bcc1850>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(clf_xgb,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     values_format='d',\n",
    "                     display_labels=['SELL', 'IGNORE', 'BUY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58      5507\n",
      "           1       0.44      0.38      0.41      4826\n",
      "           2       0.56      0.62      0.59      5532\n",
      "\n",
      "    accuracy                           0.53     15865\n",
      "   macro avg       0.53      0.53      0.52     15865\n",
      "weighted avg       0.53      0.53      0.53     15865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth' : [8],\n",
    "    'learning_rate' : [0.1],\n",
    "    'gamma' : [0.25],\n",
    "    'reg_lambda' : [1],\n",
    "}\n",
    "gsc_xgb = GridSearchCV(estimator=xgb.XGBClassifier(missing=None, \n",
    "                                                   seed=1234,\n",
    "                                                   objective='multi:softmax', \n",
    "                                                   num_class=3,\n",
    "                                                  ),\n",
    "                  param_grid=param_grid, \n",
    "                  cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  2.6min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_grid_results = gsc_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.25, 'learning_rate': 0.1, 'max_depth': 8, 'reg_lambda': 1}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {'gamma': 0.25, 'learning_rate': 0.1, 'max_depth': 8, 'reg_lambda': 1}\n",
    "gsc_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cls = gsc_xgb.best_estimator_\n",
    "#best_cls.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric=['mlogloss', 'merror'], eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2549d7d4610>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(best_cls,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     values_format='d',\n",
    "                     display_labels=['SELL', 'IGNORE', 'BUY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58      5507\n",
      "           1       0.44      0.38      0.41      4826\n",
      "           2       0.56      0.62      0.59      5532\n",
      "\n",
      "    accuracy                           0.54     15865\n",
      "   macro avg       0.53      0.53      0.53     15865\n",
      "weighted avg       0.53      0.54      0.53     15865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, best_cls.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explainer = shap.TreeExplainer(best_cls)\n",
    "shap_values = explainer.shap_values(X_test_filtered)\n",
    "shap.summary_plot(shap_values, X_test_filtered, max_display=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "up, down = [], []\n",
    "for key in data.keys():\n",
    "    stock = data[key].iloc[:4]\n",
    "    df = df_featuring_v2(stock).merge(spy_dummy, on='date', how='left')\n",
    "    try:\n",
    "        mt = model_df_v2(df)\n",
    "    except:\n",
    "        continue\n",
    "    pred = best_cls.predict(mt.drop(['cluster'], axis=1))\n",
    "    if pred == 0:\n",
    "        down.append(key)\n",
    "    elif pred == 2:\n",
    "        up.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JNJ', 'SAVA']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GS',\n",
       " 'KDP',\n",
       " 'RCL',\n",
       " 'BE',\n",
       " 'HST',\n",
       " 'SABR',\n",
       " 'SLB',\n",
       " 'AMAT',\n",
       " 'HAL',\n",
       " 'HPE',\n",
       " 'JBLU',\n",
       " 'KIM',\n",
       " 'K',\n",
       " 'PRTS',\n",
       " 'PBCT',\n",
       " 'PLUG',\n",
       " 'PCG',\n",
       " 'PYPL',\n",
       " 'C',\n",
       " 'IBM',\n",
       " 'EOG',\n",
       " 'NVDA',\n",
       " 'D',\n",
       " 'PK',\n",
       " 'MGM',\n",
       " 'DBX',\n",
       " 'BYND',\n",
       " 'NVTA',\n",
       " 'SO',\n",
       " 'TAL',\n",
       " 'COP',\n",
       " 'CTVA',\n",
       " 'BMY',\n",
       " 'KHC',\n",
       " 'MUR',\n",
       " 'AFL',\n",
       " 'CNX',\n",
       " 'WBA',\n",
       " 'RUN',\n",
       " 'UAA',\n",
       " 'MTCH',\n",
       " 'CVS',\n",
       " 'LB',\n",
       " 'DISH',\n",
       " 'APA',\n",
       " 'EXC',\n",
       " 'AA',\n",
       " 'MS',\n",
       " 'XOM',\n",
       " 'WU',\n",
       " 'JCI',\n",
       " 'LYFT',\n",
       " 'LVS',\n",
       " 'POLA',\n",
       " 'F',\n",
       " 'CFG',\n",
       " 'CL',\n",
       " 'PENN',\n",
       " 'FCX',\n",
       " 'GM',\n",
       " 'GILD',\n",
       " 'OXY',\n",
       " 'DVN',\n",
       " 'HPQ',\n",
       " 'VST',\n",
       " 'HOME',\n",
       " 'SFIX',\n",
       " 'ON',\n",
       " 'PPL',\n",
       " 'WFC',\n",
       " 'CVX',\n",
       " 'PFE',\n",
       " 'SAVE',\n",
       " 'FHN',\n",
       " 'CPB',\n",
       " 'MET',\n",
       " 'FB',\n",
       " 'GIS',\n",
       " 'BLNK',\n",
       " 'DD',\n",
       " 'GE',\n",
       " 'MDLZ',\n",
       " 'MU',\n",
       " 'KEY',\n",
       " 'PSTG',\n",
       " 'GPS',\n",
       " 'OSTK',\n",
       " 'WKHS',\n",
       " 'ALLY',\n",
       " 'NOV',\n",
       " 'CYH',\n",
       " 'AAL',\n",
       " 'TJX',\n",
       " 'LUV',\n",
       " 'GPK',\n",
       " 'FOLD',\n",
       " 'NFLX',\n",
       " 'BK',\n",
       " 'TXN',\n",
       " 'AMD',\n",
       " 'UBER',\n",
       " 'KMI',\n",
       " 'EPD',\n",
       " 'ORCL',\n",
       " 'FTI',\n",
       " 'SLM',\n",
       " 'BAC',\n",
       " 'DIS',\n",
       " 'USB',\n",
       " 'HRL']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = data['INTC'].iloc[:4]\n",
    "df = df_featuring_v2(stock).merge(spy_dummy, on='date', how='left')\n",
    "try:\n",
    "    mt = model_df_v2(df)\n",
    "except:\n",
    "    pass\n",
    "pred = best_cls.predict(mt.drop(['cluster'], axis=1))\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostClassifierMod(CatBoostClassifier):\n",
    "    def predict(self, X):\n",
    "        return super().predict(X).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifierMod(iterations=1000,\n",
    "                               loss_function='MultiClass',\n",
    "                               grow_policy='Lossguide',\n",
    "                               verbose=50\n",
    "                              )\n",
    "cat_model.set_scale_and_bias(0.25, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'learning_rate': [0.5],\n",
    "        'depth': [11],\n",
    "        'max_leaves': [60, 70, 80],\n",
    "        'l2_leaf_reg': [1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.9850893907\n",
      "bestIteration = 29\n",
      "\n",
      "0:\tloss: 0.9850894\tbest: 0.9850894 (0)\ttotal: 1.99s\tremaining: 3.98s\n",
      "\n",
      "bestTest = 0.9829759326\n",
      "bestIteration = 29\n",
      "\n",
      "1:\tloss: 0.9829759\tbest: 0.9829759 (1)\ttotal: 4.37s\tremaining: 2.19s\n",
      "\n",
      "bestTest = 0.9870625585\n",
      "bestIteration = 26\n",
      "\n",
      "2:\tloss: 0.9870626\tbest: 0.9829759 (1)\ttotal: 6.76s\tremaining: 0us\n",
      "Estimating final quality...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'params': {'max_leaves': 70,\n",
       "  'depth': 11,\n",
       "  'l2_leaf_reg': 1,\n",
       "  'learning_rate': 0.5},\n",
       " 'cv_results': defaultdict(list,\n",
       "             {'iterations': [0,\n",
       "               1,\n",
       "               2,\n",
       "               3,\n",
       "               4,\n",
       "               5,\n",
       "               6,\n",
       "               7,\n",
       "               8,\n",
       "               9,\n",
       "               10,\n",
       "               11,\n",
       "               12,\n",
       "               13,\n",
       "               14,\n",
       "               15,\n",
       "               16,\n",
       "               17,\n",
       "               18,\n",
       "               19,\n",
       "               20,\n",
       "               21,\n",
       "               22,\n",
       "               23,\n",
       "               24,\n",
       "               25,\n",
       "               26,\n",
       "               27,\n",
       "               28,\n",
       "               29,\n",
       "               30,\n",
       "               31,\n",
       "               32,\n",
       "               33,\n",
       "               34,\n",
       "               35,\n",
       "               36,\n",
       "               37,\n",
       "               38,\n",
       "               39,\n",
       "               40,\n",
       "               41,\n",
       "               42,\n",
       "               43,\n",
       "               44,\n",
       "               45,\n",
       "               46,\n",
       "               47,\n",
       "               48,\n",
       "               49],\n",
       "              'test-MultiClass-mean': [1.040426951591711,\n",
       "               1.022263077141826,\n",
       "               1.0117219886093034,\n",
       "               1.0065266068680405,\n",
       "               1.0019589540691172,\n",
       "               0.9988067446155012,\n",
       "               0.99722463132068,\n",
       "               0.9956365084562274,\n",
       "               0.9946938430197712,\n",
       "               0.993393402019807,\n",
       "               0.9923740257799828,\n",
       "               0.9911327822618518,\n",
       "               0.9905881202812857,\n",
       "               0.9899604621700462,\n",
       "               0.988790282540965,\n",
       "               0.9879915555021023,\n",
       "               0.9877396599448627,\n",
       "               0.9876909409625637,\n",
       "               0.9866257221557703,\n",
       "               0.9859252429727725,\n",
       "               0.9853221988587092,\n",
       "               0.984370409783744,\n",
       "               0.9839225741308105,\n",
       "               0.9838959283107819,\n",
       "               0.9837259447563277,\n",
       "               0.9843155308254884,\n",
       "               0.9847100214851009,\n",
       "               0.9848186935436006,\n",
       "               0.9852751847958038,\n",
       "               0.9856964373011944,\n",
       "               0.9859038594492979,\n",
       "               0.9856069944880542,\n",
       "               0.9852855573028713,\n",
       "               0.9853427900548027,\n",
       "               0.9853443633135485,\n",
       "               0.9860157158571695,\n",
       "               0.9862076362359168,\n",
       "               0.9862280570543104,\n",
       "               0.9864507404256287,\n",
       "               0.9869247695457949,\n",
       "               0.9874840717904281,\n",
       "               0.9879691473023864,\n",
       "               0.9884003254638585,\n",
       "               0.988742545999218,\n",
       "               0.9893735296346565,\n",
       "               0.9897874961348725,\n",
       "               0.990374509665509,\n",
       "               0.9909922790928983,\n",
       "               0.9911010767176983,\n",
       "               0.9915664368365432],\n",
       "              'test-MultiClass-std': [0.001098247974432451,\n",
       "               0.0019122037756664355,\n",
       "               0.0010325324802005892,\n",
       "               0.003181687509794524,\n",
       "               0.002939765401758074,\n",
       "               0.0016947264429977588,\n",
       "               0.0017605337503148848,\n",
       "               0.0014014676959376736,\n",
       "               0.002018864390582638,\n",
       "               0.001621684997357753,\n",
       "               0.0014588807144910018,\n",
       "               0.001383745367172923,\n",
       "               0.0014063478696233094,\n",
       "               0.0017261031421190321,\n",
       "               0.002199168007078149,\n",
       "               0.0026406507284827845,\n",
       "               0.002262498551853689,\n",
       "               0.002676759761272884,\n",
       "               0.0026911862263112995,\n",
       "               0.0021558844211381767,\n",
       "               0.0022364300219874004,\n",
       "               0.0014974588683242772,\n",
       "               0.0015942981860373748,\n",
       "               0.0014097356370226357,\n",
       "               0.001446415651509718,\n",
       "               0.0013329562549207745,\n",
       "               0.001938626651817851,\n",
       "               0.002147258911649964,\n",
       "               0.0018663247984810583,\n",
       "               0.0017323220734048112,\n",
       "               0.002072637628199044,\n",
       "               0.0020955571045766707,\n",
       "               0.0016655601742335108,\n",
       "               0.001858341969463332,\n",
       "               0.0016748197179473107,\n",
       "               0.0017930013479029842,\n",
       "               0.001747690418839493,\n",
       "               0.0012263515761597645,\n",
       "               0.0016367048830056967,\n",
       "               0.0022711721512692824,\n",
       "               0.001959230075821968,\n",
       "               0.0011357577160635516,\n",
       "               0.0010347097946561273,\n",
       "               0.0012155114537419024,\n",
       "               0.0019095480440431587,\n",
       "               0.002013293548842357,\n",
       "               0.0021292365387285063,\n",
       "               0.0023435054889632432,\n",
       "               0.002025683592970158,\n",
       "               0.002691073829048923],\n",
       "              'train-MultiClass-mean': [1.0376029724587619,\n",
       "               1.0166395324630073,\n",
       "               1.0033644135784396,\n",
       "               0.99513770235668,\n",
       "               0.987589195999671,\n",
       "               0.9815782759024011,\n",
       "               0.9777265097078359,\n",
       "               0.9735126475808181,\n",
       "               0.9699527141395906,\n",
       "               0.966264591398167,\n",
       "               0.9631178451757633,\n",
       "               0.9600706065295226,\n",
       "               0.9573485591811175,\n",
       "               0.954548442670298,\n",
       "               0.9507526416219193,\n",
       "               0.9483251629413495,\n",
       "               0.9457266991720287,\n",
       "               0.9433848113743343,\n",
       "               0.9396569120173809,\n",
       "               0.9365300674889095,\n",
       "               0.9334330348723986,\n",
       "               0.9302015467623694,\n",
       "               0.9263340123631014,\n",
       "               0.9230380416126461,\n",
       "               0.9188939476092135,\n",
       "               0.9152045092626913,\n",
       "               0.9113007533215574,\n",
       "               0.9074728966295208,\n",
       "               0.9035273174538284,\n",
       "               0.8990635257200217,\n",
       "               0.8952388895094024,\n",
       "               0.8909979798565958,\n",
       "               0.8862805305127273,\n",
       "               0.8821625195962405,\n",
       "               0.8777112168465346,\n",
       "               0.8740318110877894,\n",
       "               0.8701937943127359,\n",
       "               0.8663523762775828,\n",
       "               0.8633290384784255,\n",
       "               0.8592567206472471,\n",
       "               0.8559101430070358,\n",
       "               0.8522456862286191,\n",
       "               0.8483950133703613,\n",
       "               0.8442395535757342,\n",
       "               0.8408923194816378,\n",
       "               0.8374112431700884,\n",
       "               0.8339366991170948,\n",
       "               0.8301511882179019,\n",
       "               0.8272320809472093,\n",
       "               0.8238250864795501],\n",
       "              'train-MultiClass-std': [0.00041409431965514073,\n",
       "               0.0016593974880932795,\n",
       "               0.00151509521514562,\n",
       "               0.001108162163498261,\n",
       "               0.0013238610654223376,\n",
       "               0.001958860244339371,\n",
       "               0.0016785757920941497,\n",
       "               0.002234939652999004,\n",
       "               0.0017761592261542544,\n",
       "               0.0015922832343704583,\n",
       "               0.0016740158606863985,\n",
       "               0.0011111670964434905,\n",
       "               0.0011153039925789617,\n",
       "               0.0004227467014669423,\n",
       "               0.0019383071913841973,\n",
       "               0.0029468790848884182,\n",
       "               0.0024382194386299515,\n",
       "               0.0027297565763726,\n",
       "               0.0016808344606062944,\n",
       "               0.0007832958465842256,\n",
       "               0.0013903196534506568,\n",
       "               0.0015294855476224813,\n",
       "               0.0003266412589946012,\n",
       "               0.0006696786581048778,\n",
       "               0.0017443701249242507,\n",
       "               0.001762460382749395,\n",
       "               0.001783341974479955,\n",
       "               0.0016944656797146693,\n",
       "               0.0020047373148653074,\n",
       "               0.0019294007323966314,\n",
       "               0.0021251627511897726,\n",
       "               0.002199034722496407,\n",
       "               0.0018354737692245823,\n",
       "               0.0015742239419821184,\n",
       "               0.0007447950879514684,\n",
       "               0.0007917254939918784,\n",
       "               0.0007490007886871359,\n",
       "               0.0011800433707473518,\n",
       "               0.001149535356532466,\n",
       "               0.001909157583084911,\n",
       "               0.0018728004621850701,\n",
       "               0.0019172844731546932,\n",
       "               0.0024859948036507025,\n",
       "               0.001870935085787791,\n",
       "               0.0018847074339410905,\n",
       "               0.0016786185666367093,\n",
       "               0.002110278146953508,\n",
       "               0.0022008853635478625,\n",
       "               0.0015508557790093695,\n",
       "               0.0015398543319163345]})}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.grid_search(grid, X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x255098543a0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cat_model,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     values_format='d',\n",
    "                     display_labels=['SELL', 'IGNORE', 'BUY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.56      5507\n",
      "           1       0.42      0.37      0.39      4826\n",
      "           2       0.55      0.60      0.57      5532\n",
      "\n",
      "    accuracy                           0.51     15865\n",
      "   macro avg       0.51      0.51      0.51     15865\n",
      "weighted avg       0.51      0.51      0.51     15865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, cat_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "K = range(1, 21)\n",
    "kmeans_models = [KMeans(n_clusters=k, n_init=100).fit(kmeans_data) for k in K]\n",
    "dist = [model.inertia_ for model in kmeans_models]\n",
    "\n",
    "plt.plot(K, dist, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of distances')\n",
    "plt.xticks(K)\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31683"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmeans_models[K-1].labels_[kmeans_models[K-1].labels_ == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32220"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmeans_models[K-1].labels_[kmeans_models[K-1].labels_ == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmeans_models[K-1].labels_[kmeans_models[K-1].labels_ == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    0\n",
       "5    2\n",
       "6    2\n",
       "7    2\n",
       "8    1\n",
       "9    2\n",
       "Name: cluster, dtype: category\n",
       "Categories (3, int64): [0 < 1 < 2]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m['cluster'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 0, 0, 2, 1, 0, 0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_models[K-1].labels_[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['catboost',\n",
       " 'decision tree',\n",
       " 'deep learning',\n",
       " 'linear/logistic regression',\n",
       " 'random forest',\n",
       " 'svm',\n",
       " 'time series analysis',\n",
       " 'xgboost']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(['catboost', 'decision tree', 'deep learning', 'linear/logistic regression', 'random forest', 'svm', 'xgboost', 'time series analysis'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 2, ..., 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.predict(X_test).reshape((1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4320201701859439"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((cat_model.predict(X_test).reshape((1,-1)) == clf_xgb.predict(X_test)) &  (clf_xgb.predict(X_test)== y_test.values)).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 0, 1, 1, ..., 2, 0, 2, 0, 1]\n",
       "Length: 15865\n",
       "Categories (3, int64): [0 < 1 < 2]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = DeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('xgb', clf_xgb), ('cat', cat_model), ('deep_model', deep_model)],\n",
    "    voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:14:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.096419\n",
      "0:\tlearn: 1.0832533\ttotal: 21.4ms\tremaining: 21.4s\n",
      "50:\tlearn: 0.9709730\ttotal: 1.15s\tremaining: 21.4s\n",
      "100:\tlearn: 0.9527247\ttotal: 2.13s\tremaining: 18.9s\n",
      "150:\tlearn: 0.9371784\ttotal: 3.01s\tremaining: 16.9s\n",
      "200:\tlearn: 0.9231780\ttotal: 3.92s\tremaining: 15.6s\n",
      "250:\tlearn: 0.9099987\ttotal: 4.99s\tremaining: 14.9s\n",
      "300:\tlearn: 0.8986262\ttotal: 5.93s\tremaining: 13.8s\n",
      "350:\tlearn: 0.8872279\ttotal: 6.85s\tremaining: 12.7s\n",
      "400:\tlearn: 0.8764577\ttotal: 7.78s\tremaining: 11.6s\n",
      "450:\tlearn: 0.8661689\ttotal: 8.71s\tremaining: 10.6s\n",
      "500:\tlearn: 0.8567449\ttotal: 9.58s\tremaining: 9.54s\n",
      "550:\tlearn: 0.8475713\ttotal: 10.6s\tremaining: 8.65s\n",
      "600:\tlearn: 0.8384103\ttotal: 11.6s\tremaining: 7.68s\n",
      "650:\tlearn: 0.8297768\ttotal: 12.5s\tremaining: 6.7s\n",
      "700:\tlearn: 0.8214812\ttotal: 13.4s\tremaining: 5.74s\n",
      "750:\tlearn: 0.8128387\ttotal: 14.3s\tremaining: 4.76s\n",
      "800:\tlearn: 0.8046966\ttotal: 15.2s\tremaining: 3.77s\n",
      "850:\tlearn: 0.7966508\ttotal: 16.1s\tremaining: 2.81s\n",
      "900:\tlearn: 0.7886362\ttotal: 16.9s\tremaining: 1.86s\n",
      "950:\tlearn: 0.7810230\ttotal: 17.8s\tremaining: 916ms\n",
      "999:\tlearn: 0.7732915\ttotal: 18.6s\tremaining: 0us\n",
      "Epoch 1/2000\n",
      "1206/1206 [==============================] - 1s 1ms/step - loss: 1.0306 - accuracy: 0.4617 - val_loss: 0.9979 - val_accuracy: 0.5004\n",
      "Epoch 2/2000\n",
      "1206/1206 [==============================] - 1s 872us/step - loss: 0.9802 - accuracy: 0.5149 - val_loss: 0.9854 - val_accuracy: 0.5058\n",
      "Epoch 3/2000\n",
      "1206/1206 [==============================] - 1s 863us/step - loss: 0.9632 - accuracy: 0.5225 - val_loss: 0.9739 - val_accuracy: 0.5174\n",
      "Epoch 4/2000\n",
      "1206/1206 [==============================] - 1s 878us/step - loss: 0.9568 - accuracy: 0.5265 - val_loss: 0.9746 - val_accuracy: 0.5141\n",
      "Epoch 5/2000\n",
      "1206/1206 [==============================] - 1s 864us/step - loss: 0.9522 - accuracy: 0.5296 - val_loss: 0.9741 - val_accuracy: 0.5121\n",
      "Epoch 6/2000\n",
      "1206/1206 [==============================] - 1s 871us/step - loss: 0.9497 - accuracy: 0.5315 - val_loss: 0.9665 - val_accuracy: 0.5197\n",
      "Epoch 7/2000\n",
      "1206/1206 [==============================] - 1s 886us/step - loss: 0.9438 - accuracy: 0.5367 - val_loss: 0.9650 - val_accuracy: 0.5189\n",
      "Epoch 8/2000\n",
      "1206/1206 [==============================] - 1s 888us/step - loss: 0.9429 - accuracy: 0.5402 - val_loss: 0.9616 - val_accuracy: 0.5229\n",
      "Epoch 9/2000\n",
      "1206/1206 [==============================] - 1s 897us/step - loss: 0.9390 - accuracy: 0.5383 - val_loss: 0.9650 - val_accuracy: 0.5215\n",
      "Epoch 10/2000\n",
      "1206/1206 [==============================] - 1s 914us/step - loss: 0.9419 - accuracy: 0.5359 - val_loss: 0.9615 - val_accuracy: 0.5239\n",
      "Epoch 11/2000\n",
      "1206/1206 [==============================] - 1s 879us/step - loss: 0.9324 - accuracy: 0.5464 - val_loss: 0.9609 - val_accuracy: 0.5199\n",
      "Epoch 12/2000\n",
      "1206/1206 [==============================] - 1s 926us/step - loss: 0.9311 - accuracy: 0.5441 - val_loss: 0.9589 - val_accuracy: 0.5196\n",
      "Epoch 13/2000\n",
      "1206/1206 [==============================] - 1s 834us/step - loss: 0.9296 - accuracy: 0.5471 - val_loss: 0.9746 - val_accuracy: 0.5120\n",
      "Epoch 14/2000\n",
      "1206/1206 [==============================] - 1s 819us/step - loss: 0.9327 - accuracy: 0.5418 - val_loss: 0.9678 - val_accuracy: 0.5208\n",
      "Epoch 15/2000\n",
      "1206/1206 [==============================] - 1s 870us/step - loss: 0.9363 - accuracy: 0.5378 - val_loss: 0.9621 - val_accuracy: 0.5188\n",
      "Epoch 16/2000\n",
      "1206/1206 [==============================] - 1s 933us/step - loss: 0.9271 - accuracy: 0.5495 - val_loss: 0.9624 - val_accuracy: 0.5236\n",
      "Epoch 17/2000\n",
      "1206/1206 [==============================] - 1s 875us/step - loss: 0.9251 - accuracy: 0.5493 - val_loss: 0.9606 - val_accuracy: 0.5233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=None,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_class=3, num_parallel_tree=None,\n",
       "                                            objective='multi:softmax',\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None, seed=1234,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('cat',\n",
       "                              <__main__.CatBoostClassifierMod object at 0x00000255349BF7F0>),\n",
       "                             ('deep_model', DeepModel())])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2550c87c580>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(voting_clf,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     values_format='d',\n",
    "                     display_labels=['SELL', 'IGNORE', 'BUY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.59      5558\n",
      "           1       0.44      0.34      0.39      4911\n",
      "           2       0.56      0.63      0.59      5601\n",
      "\n",
      "    accuracy                           0.53     16070\n",
      "   macro avg       0.52      0.53      0.52     16070\n",
      "weighted avg       0.53      0.53      0.53     16070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, voting_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_datasets = []\n",
    "for n in range(3,10):\n",
    "    featured_dfs = []\n",
    "    for key in data.keys():\n",
    "        if data[key].empty:\n",
    "            continue\n",
    "        f_data = df_featuring_v2(data[key])\n",
    "        merge_data = f_data.merge(spy_dummy, on='date', how='left')\n",
    "        m = model_df_v2(merge_data, days=n)\n",
    "        featured_dfs.append(m)\n",
    "    blender_datasets.append( pd.concat(featured_dfs, ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:25:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.097788\n",
      "0:\tlearn: 1.0822368\ttotal: 32.8ms\tremaining: 32.8s\n",
      "50:\tlearn: 0.9669428\ttotal: 1.44s\tremaining: 26.8s\n",
      "100:\tlearn: 0.9515298\ttotal: 2.76s\tremaining: 24.6s\n",
      "150:\tlearn: 0.9393011\ttotal: 4s\tremaining: 22.5s\n",
      "200:\tlearn: 0.9281085\ttotal: 5.2s\tremaining: 20.7s\n",
      "250:\tlearn: 0.9184173\ttotal: 6.39s\tremaining: 19.1s\n",
      "300:\tlearn: 0.9098368\ttotal: 7.53s\tremaining: 17.5s\n",
      "350:\tlearn: 0.9012708\ttotal: 8.8s\tremaining: 16.3s\n",
      "400:\tlearn: 0.8935459\ttotal: 10.1s\tremaining: 15.1s\n",
      "450:\tlearn: 0.8856385\ttotal: 11.5s\tremaining: 13.9s\n",
      "500:\tlearn: 0.8781272\ttotal: 12.7s\tremaining: 12.7s\n",
      "550:\tlearn: 0.8708035\ttotal: 14.1s\tremaining: 11.5s\n",
      "600:\tlearn: 0.8641481\ttotal: 15.4s\tremaining: 10.2s\n",
      "650:\tlearn: 0.8573681\ttotal: 16.6s\tremaining: 8.91s\n",
      "700:\tlearn: 0.8507202\ttotal: 17.8s\tremaining: 7.6s\n",
      "750:\tlearn: 0.8443144\ttotal: 19.1s\tremaining: 6.33s\n",
      "800:\tlearn: 0.8379891\ttotal: 20.3s\tremaining: 5.05s\n",
      "850:\tlearn: 0.8315673\ttotal: 21.6s\tremaining: 3.77s\n",
      "900:\tlearn: 0.8254086\ttotal: 22.8s\tremaining: 2.5s\n",
      "950:\tlearn: 0.8195305\ttotal: 24s\tremaining: 1.24s\n",
      "999:\tlearn: 0.8136850\ttotal: 25.2s\tremaining: 0us\n",
      "Epoch 1/2000\n",
      "1589/1589 [==============================] - 2s 960us/step - loss: 1.0231 - accuracy: 0.4709 - val_loss: 0.9692 - val_accuracy: 0.5214\n",
      "Epoch 2/2000\n",
      "1589/1589 [==============================] - 1s 850us/step - loss: 0.9778 - accuracy: 0.5119 - val_loss: 0.9566 - val_accuracy: 0.5252\n",
      "Epoch 3/2000\n",
      "1589/1589 [==============================] - 1s 887us/step - loss: 0.9634 - accuracy: 0.5217 - val_loss: 0.9547 - val_accuracy: 0.5261\n",
      "Epoch 4/2000\n",
      "1589/1589 [==============================] - 1s 869us/step - loss: 0.9613 - accuracy: 0.5251 - val_loss: 0.9494 - val_accuracy: 0.5336\n",
      "Epoch 5/2000\n",
      "1589/1589 [==============================] - 1s 884us/step - loss: 0.9556 - accuracy: 0.5262 - val_loss: 0.9447 - val_accuracy: 0.5330\n",
      "Epoch 6/2000\n",
      "1589/1589 [==============================] - 1s 865us/step - loss: 0.9497 - accuracy: 0.5321 - val_loss: 0.9513 - val_accuracy: 0.5289\n",
      "Epoch 7/2000\n",
      "1589/1589 [==============================] - 1s 861us/step - loss: 0.9494 - accuracy: 0.5330 - val_loss: 0.9481 - val_accuracy: 0.5315\n",
      "Epoch 8/2000\n",
      "1589/1589 [==============================] - 1s 860us/step - loss: 0.9500 - accuracy: 0.5310 - val_loss: 0.9416 - val_accuracy: 0.5353\n",
      "Epoch 9/2000\n",
      "1589/1589 [==============================] - 1s 841us/step - loss: 0.9437 - accuracy: 0.5347 - val_loss: 0.9445 - val_accuracy: 0.5311\n",
      "Epoch 10/2000\n",
      "1589/1589 [==============================] - 1s 849us/step - loss: 0.9415 - accuracy: 0.5386 - val_loss: 0.9451 - val_accuracy: 0.5291\n",
      "Epoch 11/2000\n",
      "1589/1589 [==============================] - 1s 883us/step - loss: 0.9388 - accuracy: 0.5401 - val_loss: 0.9437 - val_accuracy: 0.5306\n",
      "Epoch 12/2000\n",
      "1589/1589 [==============================] - 1s 864us/step - loss: 0.9346 - accuracy: 0.5453 - val_loss: 0.9417 - val_accuracy: 0.5319\n",
      "Epoch 13/2000\n",
      "1589/1589 [==============================] - 1s 866us/step - loss: 0.9388 - accuracy: 0.5373 - val_loss: 0.9425 - val_accuracy: 0.5395\n",
      "[21:26:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.097788\n",
      "0:\tlearn: 1.0830526\ttotal: 40.3ms\tremaining: 40.3s\n",
      "50:\tlearn: 0.9690820\ttotal: 2.41s\tremaining: 44.8s\n",
      "100:\tlearn: 0.9525851\ttotal: 4.51s\tremaining: 40.2s\n",
      "150:\tlearn: 0.9393579\ttotal: 6.46s\tremaining: 36.3s\n",
      "200:\tlearn: 0.9271709\ttotal: 8.16s\tremaining: 32.4s\n",
      "250:\tlearn: 0.9165035\ttotal: 9.77s\tremaining: 29.1s\n",
      "300:\tlearn: 0.9068418\ttotal: 11.4s\tremaining: 26.4s\n",
      "350:\tlearn: 0.8973098\ttotal: 13s\tremaining: 24s\n",
      "400:\tlearn: 0.8883085\ttotal: 14.6s\tremaining: 21.8s\n",
      "450:\tlearn: 0.8798609\ttotal: 16.3s\tremaining: 19.9s\n",
      "500:\tlearn: 0.8718310\ttotal: 18.2s\tremaining: 18.1s\n",
      "550:\tlearn: 0.8644512\ttotal: 20s\tremaining: 16.3s\n",
      "600:\tlearn: 0.8571050\ttotal: 22s\tremaining: 14.6s\n",
      "650:\tlearn: 0.8493754\ttotal: 23.6s\tremaining: 12.7s\n",
      "700:\tlearn: 0.8420822\ttotal: 25.2s\tremaining: 10.8s\n",
      "750:\tlearn: 0.8353716\ttotal: 26.8s\tremaining: 8.9s\n",
      "800:\tlearn: 0.8285006\ttotal: 28.4s\tremaining: 7.05s\n",
      "850:\tlearn: 0.8218950\ttotal: 30s\tremaining: 5.25s\n",
      "900:\tlearn: 0.8155691\ttotal: 31.6s\tremaining: 3.47s\n",
      "950:\tlearn: 0.8089980\ttotal: 33.4s\tremaining: 1.72s\n",
      "999:\tlearn: 0.8027884\ttotal: 35.1s\tremaining: 0us\n",
      "Epoch 1/2000\n",
      "1589/1589 [==============================] - 2s 935us/step - loss: 1.0245 - accuracy: 0.4730 - val_loss: 0.9755 - val_accuracy: 0.5203\n",
      "Epoch 2/2000\n",
      "1589/1589 [==============================] - 1s 853us/step - loss: 0.9757 - accuracy: 0.5139 - val_loss: 0.9619 - val_accuracy: 0.5223\n",
      "Epoch 3/2000\n",
      "1589/1589 [==============================] - 1s 779us/step - loss: 0.9631 - accuracy: 0.5243 - val_loss: 0.9525 - val_accuracy: 0.5319\n",
      "Epoch 4/2000\n",
      "1589/1589 [==============================] - 1s 803us/step - loss: 0.9656 - accuracy: 0.5234 - val_loss: 0.9544 - val_accuracy: 0.5297\n",
      "Epoch 5/2000\n",
      "1589/1589 [==============================] - 1s 805us/step - loss: 0.9559 - accuracy: 0.5307 - val_loss: 0.9462 - val_accuracy: 0.5318\n",
      "Epoch 6/2000\n",
      "1589/1589 [==============================] - 1s 778us/step - loss: 0.9557 - accuracy: 0.5295 - val_loss: 0.9485 - val_accuracy: 0.5353\n",
      "Epoch 7/2000\n",
      "1589/1589 [==============================] - 1s 776us/step - loss: 0.9484 - accuracy: 0.5358 - val_loss: 0.9565 - val_accuracy: 0.5235\n",
      "Epoch 8/2000\n",
      "1589/1589 [==============================] - 1s 833us/step - loss: 0.9454 - accuracy: 0.5362 - val_loss: 0.9417 - val_accuracy: 0.5356\n",
      "Epoch 9/2000\n",
      "1589/1589 [==============================] - 1s 868us/step - loss: 0.9433 - accuracy: 0.5327 - val_loss: 0.9410 - val_accuracy: 0.5393\n",
      "Epoch 10/2000\n",
      "1589/1589 [==============================] - 1s 886us/step - loss: 0.9402 - accuracy: 0.5367 - val_loss: 0.9396 - val_accuracy: 0.5395\n",
      "Epoch 11/2000\n",
      "1589/1589 [==============================] - 1s 846us/step - loss: 0.9379 - accuracy: 0.5411 - val_loss: 0.9394 - val_accuracy: 0.5388\n",
      "Epoch 12/2000\n",
      "1589/1589 [==============================] - 1s 846us/step - loss: 0.9369 - accuracy: 0.5398 - val_loss: 0.9383 - val_accuracy: 0.5407\n",
      "Epoch 13/2000\n",
      "1589/1589 [==============================] - 1s 847us/step - loss: 0.9366 - accuracy: 0.5366 - val_loss: 0.9360 - val_accuracy: 0.5436\n",
      "Epoch 14/2000\n",
      "1589/1589 [==============================] - 1s 820us/step - loss: 0.9276 - accuracy: 0.5505 - val_loss: 0.9395 - val_accuracy: 0.5373\n",
      "Epoch 15/2000\n",
      "1589/1589 [==============================] - 1s 813us/step - loss: 0.9324 - accuracy: 0.5407 - val_loss: 0.9401 - val_accuracy: 0.5356\n",
      "Epoch 16/2000\n",
      "1589/1589 [==============================] - 1s 832us/step - loss: 0.9314 - accuracy: 0.5431 - val_loss: 0.9428 - val_accuracy: 0.5385\n",
      "Epoch 17/2000\n",
      "1589/1589 [==============================] - 1s 832us/step - loss: 0.9317 - accuracy: 0.5412 - val_loss: 0.9394 - val_accuracy: 0.5359\n",
      "Epoch 18/2000\n",
      "1589/1589 [==============================] - 1s 833us/step - loss: 0.9270 - accuracy: 0.5449 - val_loss: 0.9363 - val_accuracy: 0.5411\n",
      "[21:27:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.097788\n",
      "0:\tlearn: 1.0827673\ttotal: 46.8ms\tremaining: 46.7s\n",
      "50:\tlearn: 0.9693151\ttotal: 2.52s\tremaining: 46.9s\n",
      "100:\tlearn: 0.9534322\ttotal: 4.79s\tremaining: 42.6s\n",
      "150:\tlearn: 0.9394948\ttotal: 6.77s\tremaining: 38.1s\n",
      "200:\tlearn: 0.9268569\ttotal: 8.71s\tremaining: 34.6s\n",
      "250:\tlearn: 0.9154067\ttotal: 10.6s\tremaining: 31.7s\n",
      "300:\tlearn: 0.9050633\ttotal: 12.7s\tremaining: 29.4s\n",
      "350:\tlearn: 0.8955380\ttotal: 14.8s\tremaining: 27.3s\n",
      "400:\tlearn: 0.8863387\ttotal: 16.8s\tremaining: 25.1s\n",
      "450:\tlearn: 0.8777406\ttotal: 18.8s\tremaining: 22.9s\n",
      "500:\tlearn: 0.8684492\ttotal: 20.6s\tremaining: 20.5s\n",
      "550:\tlearn: 0.8602862\ttotal: 22.4s\tremaining: 18.3s\n",
      "600:\tlearn: 0.8524226\ttotal: 24.2s\tremaining: 16.1s\n",
      "650:\tlearn: 0.8448665\ttotal: 26s\tremaining: 13.9s\n",
      "700:\tlearn: 0.8372604\ttotal: 27.8s\tremaining: 11.9s\n",
      "750:\tlearn: 0.8298372\ttotal: 29.8s\tremaining: 9.89s\n",
      "800:\tlearn: 0.8219744\ttotal: 31.7s\tremaining: 7.88s\n",
      "850:\tlearn: 0.8151773\ttotal: 33.6s\tremaining: 5.89s\n",
      "900:\tlearn: 0.8081022\ttotal: 35.5s\tremaining: 3.9s\n",
      "950:\tlearn: 0.8012668\ttotal: 37.2s\tremaining: 1.92s\n",
      "999:\tlearn: 0.7945639\ttotal: 39s\tremaining: 0us\n",
      "Epoch 1/2000\n",
      "1589/1589 [==============================] - 2s 946us/step - loss: 1.0259 - accuracy: 0.4757 - val_loss: 0.9784 - val_accuracy: 0.5157\n",
      "Epoch 2/2000\n",
      "1589/1589 [==============================] - 1s 863us/step - loss: 0.9863 - accuracy: 0.5086 - val_loss: 0.9610 - val_accuracy: 0.5262\n",
      "Epoch 3/2000\n",
      "1589/1589 [==============================] - 1s 870us/step - loss: 0.9703 - accuracy: 0.5167 - val_loss: 0.9585 - val_accuracy: 0.5263\n",
      "Epoch 4/2000\n",
      "1589/1589 [==============================] - 1s 923us/step - loss: 0.9615 - accuracy: 0.5211 - val_loss: 0.9493 - val_accuracy: 0.5304\n",
      "Epoch 5/2000\n",
      "1589/1589 [==============================] - 1s 913us/step - loss: 0.9598 - accuracy: 0.5232 - val_loss: 0.9480 - val_accuracy: 0.5363\n",
      "Epoch 6/2000\n",
      "1589/1589 [==============================] - 1s 911us/step - loss: 0.9487 - accuracy: 0.5326 - val_loss: 0.9595 - val_accuracy: 0.5255\n",
      "Epoch 7/2000\n",
      "1589/1589 [==============================] - 1s 940us/step - loss: 0.9465 - accuracy: 0.5342 - val_loss: 0.9464 - val_accuracy: 0.5320\n",
      "Epoch 8/2000\n",
      "1589/1589 [==============================] - 1s 833us/step - loss: 0.9430 - accuracy: 0.5371 - val_loss: 0.9528 - val_accuracy: 0.5264\n",
      "Epoch 9/2000\n",
      "1589/1589 [==============================] - 1s 823us/step - loss: 0.9433 - accuracy: 0.5372 - val_loss: 0.9401 - val_accuracy: 0.5389\n",
      "Epoch 10/2000\n",
      "1589/1589 [==============================] - 1s 837us/step - loss: 0.9411 - accuracy: 0.5334 - val_loss: 0.9390 - val_accuracy: 0.5398\n",
      "Epoch 11/2000\n",
      "1589/1589 [==============================] - 1s 830us/step - loss: 0.9374 - accuracy: 0.5394 - val_loss: 0.9423 - val_accuracy: 0.5365\n",
      "Epoch 12/2000\n",
      "1589/1589 [==============================] - 1s 865us/step - loss: 0.9324 - accuracy: 0.5437 - val_loss: 0.9367 - val_accuracy: 0.5378\n",
      "Epoch 13/2000\n",
      "1589/1589 [==============================] - 1s 866us/step - loss: 0.9337 - accuracy: 0.5399 - val_loss: 0.9383 - val_accuracy: 0.5321\n",
      "Epoch 14/2000\n",
      "1589/1589 [==============================] - 1s 847us/step - loss: 0.9290 - accuracy: 0.5459 - val_loss: 0.9369 - val_accuracy: 0.5364\n",
      "Epoch 15/2000\n",
      "1589/1589 [==============================] - 1s 905us/step - loss: 0.9234 - accuracy: 0.5482 - val_loss: 0.9389 - val_accuracy: 0.5433\n",
      "Epoch 16/2000\n",
      "1589/1589 [==============================] - 1s 919us/step - loss: 0.9235 - accuracy: 0.5471 - val_loss: 0.9346 - val_accuracy: 0.5414\n",
      "Epoch 17/2000\n",
      "1589/1589 [==============================] - 1s 909us/step - loss: 0.9227 - accuracy: 0.5510 - val_loss: 0.9391 - val_accuracy: 0.5400\n",
      "Epoch 18/2000\n",
      "1589/1589 [==============================] - 1s 924us/step - loss: 0.9209 - accuracy: 0.5541 - val_loss: 0.9350 - val_accuracy: 0.5384\n",
      "Epoch 19/2000\n",
      "1589/1589 [==============================] - 1s 904us/step - loss: 0.9213 - accuracy: 0.5482 - val_loss: 0.9405 - val_accuracy: 0.5362\n",
      "Epoch 20/2000\n",
      "1589/1589 [==============================] - 1s 859us/step - loss: 0.9158 - accuracy: 0.5540 - val_loss: 0.9341 - val_accuracy: 0.5411\n",
      "Epoch 21/2000\n",
      "1589/1589 [==============================] - 1s 857us/step - loss: 0.9104 - accuracy: 0.5556 - val_loss: 0.9363 - val_accuracy: 0.5425\n",
      "Epoch 22/2000\n",
      "1589/1589 [==============================] - 1s 845us/step - loss: 0.9168 - accuracy: 0.5517 - val_loss: 0.9391 - val_accuracy: 0.5372\n",
      "Epoch 23/2000\n",
      "1589/1589 [==============================] - 1s 837us/step - loss: 0.9115 - accuracy: 0.5549 - val_loss: 0.9351 - val_accuracy: 0.5422\n",
      "Epoch 24/2000\n",
      "1589/1589 [==============================] - 1s 830us/step - loss: 0.9179 - accuracy: 0.5496 - val_loss: 0.9413 - val_accuracy: 0.5405\n",
      "Epoch 25/2000\n",
      "1589/1589 [==============================] - 1s 830us/step - loss: 0.9096 - accuracy: 0.5608 - val_loss: 0.9362 - val_accuracy: 0.5446\n",
      "[21:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.097788\n",
      "0:\tlearn: 1.0837795\ttotal: 51.6ms\tremaining: 51.6s\n",
      "50:\tlearn: 0.9731581\ttotal: 2.6s\tremaining: 48.4s\n",
      "100:\tlearn: 0.9546072\ttotal: 5.19s\tremaining: 46.2s\n",
      "150:\tlearn: 0.9393951\ttotal: 7.98s\tremaining: 44.9s\n",
      "200:\tlearn: 0.9267736\ttotal: 10.5s\tremaining: 41.7s\n",
      "250:\tlearn: 0.9152459\ttotal: 12.7s\tremaining: 37.9s\n",
      "300:\tlearn: 0.9054168\ttotal: 14.8s\tremaining: 34.3s\n",
      "350:\tlearn: 0.8946371\ttotal: 16.8s\tremaining: 31s\n",
      "400:\tlearn: 0.8850102\ttotal: 18.7s\tremaining: 28s\n",
      "450:\tlearn: 0.8757201\ttotal: 20.8s\tremaining: 25.3s\n",
      "500:\tlearn: 0.8668995\ttotal: 23.3s\tremaining: 23.2s\n",
      "550:\tlearn: 0.8583690\ttotal: 25.6s\tremaining: 20.9s\n",
      "600:\tlearn: 0.8498932\ttotal: 27.8s\tremaining: 18.5s\n",
      "650:\tlearn: 0.8417709\ttotal: 29.8s\tremaining: 16s\n",
      "700:\tlearn: 0.8341856\ttotal: 31.7s\tremaining: 13.5s\n",
      "750:\tlearn: 0.8263536\ttotal: 33.7s\tremaining: 11.2s\n",
      "800:\tlearn: 0.8184489\ttotal: 35.8s\tremaining: 8.9s\n",
      "850:\tlearn: 0.8113180\ttotal: 38.1s\tremaining: 6.66s\n",
      "900:\tlearn: 0.8041789\ttotal: 40.3s\tremaining: 4.42s\n",
      "950:\tlearn: 0.7969085\ttotal: 42.5s\tremaining: 2.19s\n",
      "999:\tlearn: 0.7900009\ttotal: 44.6s\tremaining: 0us\n",
      "Epoch 1/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 1.0288 - accuracy: 0.4671 - val_loss: 0.9854 - val_accuracy: 0.5106\n",
      "Epoch 2/2000\n",
      "1589/1589 [==============================] - 1s 798us/step - loss: 0.9862 - accuracy: 0.5040 - val_loss: 0.9689 - val_accuracy: 0.5251\n",
      "Epoch 3/2000\n",
      "1589/1589 [==============================] - 1s 852us/step - loss: 0.9684 - accuracy: 0.5213 - val_loss: 0.9763 - val_accuracy: 0.5170\n",
      "Epoch 4/2000\n",
      "1589/1589 [==============================] - 1s 831us/step - loss: 0.9616 - accuracy: 0.5258 - val_loss: 0.9536 - val_accuracy: 0.5280\n",
      "Epoch 5/2000\n",
      "1589/1589 [==============================] - 1s 858us/step - loss: 0.9586 - accuracy: 0.5259 - val_loss: 0.9506 - val_accuracy: 0.5306\n",
      "Epoch 6/2000\n",
      "1589/1589 [==============================] - 2s 950us/step - loss: 0.9574 - accuracy: 0.5262 - val_loss: 0.9512 - val_accuracy: 0.5296\n",
      "Epoch 7/2000\n",
      "1589/1589 [==============================] - 1s 854us/step - loss: 0.9504 - accuracy: 0.5340 - val_loss: 0.9518 - val_accuracy: 0.5289\n",
      "Epoch 8/2000\n",
      "1589/1589 [==============================] - 1s 858us/step - loss: 0.9513 - accuracy: 0.5299 - val_loss: 0.9472 - val_accuracy: 0.5312\n",
      "Epoch 9/2000\n",
      "1589/1589 [==============================] - 1s 893us/step - loss: 0.9419 - accuracy: 0.5341 - val_loss: 0.9486 - val_accuracy: 0.5230\n",
      "Epoch 10/2000\n",
      "1589/1589 [==============================] - 1s 832us/step - loss: 0.9418 - accuracy: 0.5351 - val_loss: 0.9391 - val_accuracy: 0.5385\n",
      "Epoch 11/2000\n",
      "1589/1589 [==============================] - 1s 786us/step - loss: 0.9371 - accuracy: 0.5398 - val_loss: 0.9421 - val_accuracy: 0.5326\n",
      "Epoch 12/2000\n",
      "1589/1589 [==============================] - 1s 754us/step - loss: 0.9309 - accuracy: 0.5437 - val_loss: 0.9404 - val_accuracy: 0.5369\n",
      "Epoch 13/2000\n",
      "1589/1589 [==============================] - 1s 822us/step - loss: 0.9373 - accuracy: 0.5370 - val_loss: 0.9393 - val_accuracy: 0.5389\n",
      "Epoch 14/2000\n",
      "1589/1589 [==============================] - 1s 826us/step - loss: 0.9317 - accuracy: 0.5472 - val_loss: 0.9503 - val_accuracy: 0.5348\n",
      "Epoch 15/2000\n",
      "1589/1589 [==============================] - 1s 816us/step - loss: 0.9293 - accuracy: 0.5410 - val_loss: 0.9370 - val_accuracy: 0.5368\n",
      "Epoch 16/2000\n",
      "1589/1589 [==============================] - 1s 846us/step - loss: 0.9309 - accuracy: 0.5433 - val_loss: 0.9404 - val_accuracy: 0.5397\n",
      "Epoch 17/2000\n",
      "1589/1589 [==============================] - 1s 938us/step - loss: 0.9240 - accuracy: 0.5479 - val_loss: 0.9373 - val_accuracy: 0.5405\n",
      "Epoch 18/2000\n",
      "1589/1589 [==============================] - 1s 934us/step - loss: 0.9236 - accuracy: 0.5460 - val_loss: 0.9420 - val_accuracy: 0.5358\n",
      "Epoch 19/2000\n",
      "1589/1589 [==============================] - 1s 924us/step - loss: 0.9191 - accuracy: 0.5496 - val_loss: 0.9350 - val_accuracy: 0.5437\n",
      "Epoch 20/2000\n",
      "1589/1589 [==============================] - 1s 931us/step - loss: 0.9235 - accuracy: 0.5502 - val_loss: 0.9372 - val_accuracy: 0.5397\n",
      "Epoch 21/2000\n",
      "1589/1589 [==============================] - 2s 971us/step - loss: 0.9207 - accuracy: 0.5469 - val_loss: 0.9452 - val_accuracy: 0.5348\n",
      "Epoch 22/2000\n",
      "1589/1589 [==============================] - 1s 873us/step - loss: 0.9132 - accuracy: 0.5550 - val_loss: 0.9376 - val_accuracy: 0.5384\n",
      "Epoch 23/2000\n",
      "1589/1589 [==============================] - 1s 841us/step - loss: 0.9140 - accuracy: 0.5552 - val_loss: 0.9380 - val_accuracy: 0.5374\n",
      "Epoch 24/2000\n",
      "1589/1589 [==============================] - 1s 824us/step - loss: 0.9172 - accuracy: 0.5519 - val_loss: 0.9384 - val_accuracy: 0.5435\n",
      "[21:31:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.097788\n",
      "0:\tlearn: 1.0833030\ttotal: 49.7ms\tremaining: 49.6s\n",
      "50:\tlearn: 0.9755228\ttotal: 2.54s\tremaining: 47.4s\n",
      "100:\tlearn: 0.9553602\ttotal: 5.08s\tremaining: 45.3s\n",
      "150:\tlearn: 0.9399625\ttotal: 8.03s\tremaining: 45.2s\n",
      "200:\tlearn: 0.9257140\ttotal: 10.7s\tremaining: 42.4s\n",
      "250:\tlearn: 0.9140318\ttotal: 12.9s\tremaining: 38.6s\n",
      "300:\tlearn: 0.9029738\ttotal: 15s\tremaining: 34.8s\n",
      "350:\tlearn: 0.8920510\ttotal: 17.1s\tremaining: 31.6s\n",
      "400:\tlearn: 0.8824128\ttotal: 19.2s\tremaining: 28.6s\n",
      "450:\tlearn: 0.8726122\ttotal: 21.3s\tremaining: 25.9s\n",
      "500:\tlearn: 0.8634644\ttotal: 23.7s\tremaining: 23.6s\n",
      "550:\tlearn: 0.8543865\ttotal: 26.2s\tremaining: 21.3s\n",
      "600:\tlearn: 0.8455860\ttotal: 28.4s\tremaining: 18.9s\n",
      "650:\tlearn: 0.8370518\ttotal: 30.5s\tremaining: 16.4s\n",
      "700:\tlearn: 0.8288484\ttotal: 32.6s\tremaining: 13.9s\n",
      "750:\tlearn: 0.8209737\ttotal: 34.8s\tremaining: 11.5s\n",
      "800:\tlearn: 0.8130755\ttotal: 37s\tremaining: 9.19s\n",
      "850:\tlearn: 0.8052120\ttotal: 39.5s\tremaining: 6.91s\n",
      "900:\tlearn: 0.7979046\ttotal: 41.9s\tremaining: 4.6s\n",
      "950:\tlearn: 0.7903618\ttotal: 44.3s\tremaining: 2.28s\n",
      "999:\tlearn: 0.7833816\ttotal: 46.3s\tremaining: 0us\n",
      "Epoch 1/2000\n",
      "1589/1589 [==============================] - 2s 901us/step - loss: 1.0329 - accuracy: 0.4632 - val_loss: 0.9912 - val_accuracy: 0.5101\n",
      "Epoch 2/2000\n",
      "1589/1589 [==============================] - 1s 785us/step - loss: 0.9916 - accuracy: 0.5041 - val_loss: 0.9755 - val_accuracy: 0.5222\n",
      "Epoch 3/2000\n",
      "1589/1589 [==============================] - 1s 831us/step - loss: 0.9761 - accuracy: 0.5182 - val_loss: 0.9610 - val_accuracy: 0.5263\n",
      "Epoch 4/2000\n",
      "1589/1589 [==============================] - 1s 843us/step - loss: 0.9681 - accuracy: 0.5213 - val_loss: 0.9549 - val_accuracy: 0.5317\n",
      "Epoch 5/2000\n",
      "1589/1589 [==============================] - 1s 843us/step - loss: 0.9593 - accuracy: 0.5293 - val_loss: 0.9499 - val_accuracy: 0.5325\n",
      "Epoch 6/2000\n",
      "1589/1589 [==============================] - 1s 833us/step - loss: 0.9518 - accuracy: 0.5337 - val_loss: 0.9486 - val_accuracy: 0.5343\n",
      "Epoch 7/2000\n",
      "1589/1589 [==============================] - 1s 817us/step - loss: 0.9511 - accuracy: 0.5327 - val_loss: 0.9561 - val_accuracy: 0.5243\n",
      "Epoch 8/2000\n",
      "1589/1589 [==============================] - 1s 851us/step - loss: 0.9464 - accuracy: 0.5348 - val_loss: 0.9439 - val_accuracy: 0.5294\n",
      "Epoch 9/2000\n",
      "1589/1589 [==============================] - 1s 844us/step - loss: 0.9451 - accuracy: 0.5373 - val_loss: 0.9407 - val_accuracy: 0.5359\n",
      "Epoch 10/2000\n",
      "1589/1589 [==============================] - 1s 805us/step - loss: 0.9430 - accuracy: 0.5387 - val_loss: 0.9438 - val_accuracy: 0.5366\n",
      "Epoch 11/2000\n",
      "1589/1589 [==============================] - 1s 748us/step - loss: 0.9347 - accuracy: 0.5427 - val_loss: 0.9398 - val_accuracy: 0.5385\n",
      "Epoch 12/2000\n",
      "1589/1589 [==============================] - 1s 771us/step - loss: 0.9313 - accuracy: 0.5442 - val_loss: 0.9394 - val_accuracy: 0.5389\n",
      "Epoch 13/2000\n",
      "1589/1589 [==============================] - 1s 798us/step - loss: 0.9272 - accuracy: 0.5465 - val_loss: 0.9382 - val_accuracy: 0.5405\n",
      "Epoch 14/2000\n",
      "1589/1589 [==============================] - 1s 729us/step - loss: 0.9280 - accuracy: 0.5485 - val_loss: 0.9389 - val_accuracy: 0.5392\n",
      "Epoch 15/2000\n",
      "1589/1589 [==============================] - 1s 792us/step - loss: 0.9245 - accuracy: 0.5483 - val_loss: 0.9474 - val_accuracy: 0.5352\n",
      "Epoch 16/2000\n",
      "1589/1589 [==============================] - 1s 788us/step - loss: 0.9291 - accuracy: 0.5474 - val_loss: 0.9382 - val_accuracy: 0.5415\n",
      "Epoch 17/2000\n",
      "1589/1589 [==============================] - 1s 850us/step - loss: 0.9224 - accuracy: 0.5484 - val_loss: 0.9361 - val_accuracy: 0.5419\n",
      "Epoch 18/2000\n",
      "1589/1589 [==============================] - 1s 871us/step - loss: 0.9204 - accuracy: 0.5537 - val_loss: 0.9406 - val_accuracy: 0.5393\n",
      "Epoch 19/2000\n",
      "1589/1589 [==============================] - 1s 831us/step - loss: 0.9204 - accuracy: 0.5514 - val_loss: 0.9393 - val_accuracy: 0.5382\n",
      "Epoch 20/2000\n",
      "1589/1589 [==============================] - 1s 848us/step - loss: 0.9164 - accuracy: 0.5544 - val_loss: 0.9370 - val_accuracy: 0.5437\n",
      "Epoch 21/2000\n",
      "1589/1589 [==============================] - 1s 869us/step - loss: 0.9177 - accuracy: 0.5497 - val_loss: 0.9361 - val_accuracy: 0.5444\n",
      "Epoch 22/2000\n",
      "1589/1589 [==============================] - 2s 961us/step - loss: 0.9151 - accuracy: 0.5552 - val_loss: 0.9351 - val_accuracy: 0.5419\n",
      "Epoch 23/2000\n",
      "1589/1589 [==============================] - 1s 927us/step - loss: 0.9158 - accuracy: 0.5538 - val_loss: 0.9435 - val_accuracy: 0.5396\n",
      "Epoch 24/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9142 - accuracy: 0.5560 - val_loss: 0.9375 - val_accuracy: 0.5416\n",
      "Epoch 25/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9091 - accuracy: 0.5595 - val_loss: 0.9375 - val_accuracy: 0.5418\n",
      "Epoch 26/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9048 - accuracy: 0.5632 - val_loss: 0.9367 - val_accuracy: 0.5422\n",
      "Epoch 27/2000\n",
      "1589/1589 [==============================] - 1s 874us/step - loss: 0.9071 - accuracy: 0.5603 - val_loss: 0.9353 - val_accuracy: 0.5426\n",
      "[21:33:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.097788\n",
      "0:\tlearn: 1.0843378\ttotal: 48.4ms\tremaining: 48.4s\n",
      "50:\tlearn: 0.9759116\ttotal: 2.9s\tremaining: 54s\n",
      "100:\tlearn: 0.9549444\ttotal: 5.53s\tremaining: 49.2s\n",
      "150:\tlearn: 0.9390910\ttotal: 7.75s\tremaining: 43.5s\n",
      "200:\tlearn: 0.9241007\ttotal: 9.93s\tremaining: 39.5s\n",
      "250:\tlearn: 0.9114484\ttotal: 12.1s\tremaining: 36.1s\n",
      "300:\tlearn: 0.9004227\ttotal: 14.6s\tremaining: 33.8s\n",
      "350:\tlearn: 0.8894133\ttotal: 17s\tremaining: 31.5s\n",
      "400:\tlearn: 0.8797047\ttotal: 19.8s\tremaining: 29.6s\n",
      "450:\tlearn: 0.8695260\ttotal: 22s\tremaining: 26.8s\n",
      "500:\tlearn: 0.8602705\ttotal: 24.2s\tremaining: 24.1s\n",
      "550:\tlearn: 0.8515103\ttotal: 26.3s\tremaining: 21.5s\n",
      "600:\tlearn: 0.8429719\ttotal: 28.5s\tremaining: 18.9s\n",
      "650:\tlearn: 0.8346117\ttotal: 31.1s\tremaining: 16.6s\n",
      "700:\tlearn: 0.8263077\ttotal: 33.7s\tremaining: 14.4s\n",
      "750:\tlearn: 0.8180831\ttotal: 36.1s\tremaining: 12s\n",
      "800:\tlearn: 0.8104218\ttotal: 38.3s\tremaining: 9.51s\n",
      "850:\tlearn: 0.8025983\ttotal: 40.5s\tremaining: 7.09s\n",
      "900:\tlearn: 0.7950314\ttotal: 42.8s\tremaining: 4.7s\n",
      "950:\tlearn: 0.7874954\ttotal: 45.2s\tremaining: 2.33s\n",
      "999:\tlearn: 0.7801534\ttotal: 47.7s\tremaining: 0us\n",
      "Epoch 1/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 1.0301 - accuracy: 0.4657 - val_loss: 0.9871 - val_accuracy: 0.5114\n",
      "Epoch 2/2000\n",
      "1589/1589 [==============================] - 1s 915us/step - loss: 0.9908 - accuracy: 0.5037 - val_loss: 0.9698 - val_accuracy: 0.5248\n",
      "Epoch 3/2000\n",
      "1589/1589 [==============================] - 1s 823us/step - loss: 0.9766 - accuracy: 0.5191 - val_loss: 0.9607 - val_accuracy: 0.5300\n",
      "Epoch 4/2000\n",
      "1589/1589 [==============================] - 1s 813us/step - loss: 0.9677 - accuracy: 0.5225 - val_loss: 0.9543 - val_accuracy: 0.5336\n",
      "Epoch 5/2000\n",
      "1589/1589 [==============================] - 1s 818us/step - loss: 0.9599 - accuracy: 0.5263 - val_loss: 0.9507 - val_accuracy: 0.5340\n",
      "Epoch 6/2000\n",
      "1589/1589 [==============================] - 1s 852us/step - loss: 0.9566 - accuracy: 0.5294 - val_loss: 0.9439 - val_accuracy: 0.5338\n",
      "Epoch 7/2000\n",
      "1589/1589 [==============================] - 1s 868us/step - loss: 0.9529 - accuracy: 0.5303 - val_loss: 0.9422 - val_accuracy: 0.5387\n",
      "Epoch 8/2000\n",
      "1589/1589 [==============================] - 1s 837us/step - loss: 0.9466 - accuracy: 0.5341 - val_loss: 0.9427 - val_accuracy: 0.5362\n",
      "Epoch 9/2000\n",
      "1589/1589 [==============================] - 2s 964us/step - loss: 0.9456 - accuracy: 0.5359 - val_loss: 0.9423 - val_accuracy: 0.5420\n",
      "Epoch 10/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9416 - accuracy: 0.5362 - val_loss: 0.9419 - val_accuracy: 0.5386\n",
      "Epoch 11/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9390 - accuracy: 0.5387 - val_loss: 0.9401 - val_accuracy: 0.5390\n",
      "Epoch 12/2000\n",
      "1589/1589 [==============================] - 2s 983us/step - loss: 0.9333 - accuracy: 0.5427 - val_loss: 0.9493 - val_accuracy: 0.5323\n",
      "Epoch 13/2000\n",
      "1589/1589 [==============================] - 2s 952us/step - loss: 0.9372 - accuracy: 0.5395 - val_loss: 0.9413 - val_accuracy: 0.5385\n",
      "Epoch 14/2000\n",
      "1589/1589 [==============================] - 1s 884us/step - loss: 0.9326 - accuracy: 0.5449 - val_loss: 0.9369 - val_accuracy: 0.5408\n",
      "Epoch 15/2000\n",
      "1589/1589 [==============================] - 1s 889us/step - loss: 0.9316 - accuracy: 0.5445 - val_loss: 0.9427 - val_accuracy: 0.5379\n",
      "Epoch 16/2000\n",
      "1589/1589 [==============================] - 1s 857us/step - loss: 0.9215 - accuracy: 0.5499 - val_loss: 0.9363 - val_accuracy: 0.5424\n",
      "Epoch 17/2000\n",
      "1589/1589 [==============================] - 1s 820us/step - loss: 0.9250 - accuracy: 0.5485 - val_loss: 0.9423 - val_accuracy: 0.5374\n",
      "Epoch 18/2000\n",
      "1589/1589 [==============================] - 1s 842us/step - loss: 0.9215 - accuracy: 0.5471 - val_loss: 0.9383 - val_accuracy: 0.5407\n",
      "Epoch 19/2000\n",
      "1589/1589 [==============================] - 1s 851us/step - loss: 0.9208 - accuracy: 0.5536 - val_loss: 0.9351 - val_accuracy: 0.5444\n",
      "Epoch 20/2000\n",
      "1589/1589 [==============================] - 2s 961us/step - loss: 0.9236 - accuracy: 0.5512 - val_loss: 0.9481 - val_accuracy: 0.5375\n",
      "Epoch 21/2000\n",
      "1589/1589 [==============================] - 2s 967us/step - loss: 0.9194 - accuracy: 0.5495 - val_loss: 0.9374 - val_accuracy: 0.5416\n",
      "Epoch 22/2000\n",
      "1589/1589 [==============================] - 1s 943us/step - loss: 0.9141 - accuracy: 0.5537 - val_loss: 0.9319 - val_accuracy: 0.5461\n",
      "Epoch 23/2000\n",
      "1589/1589 [==============================] - 2s 949us/step - loss: 0.9088 - accuracy: 0.5619 - val_loss: 0.9377 - val_accuracy: 0.5391\n",
      "Epoch 24/2000\n",
      "1589/1589 [==============================] - 1s 900us/step - loss: 0.9090 - accuracy: 0.5590 - val_loss: 0.9357 - val_accuracy: 0.5456\n",
      "Epoch 25/2000\n",
      "1589/1589 [==============================] - 1s 855us/step - loss: 0.9067 - accuracy: 0.5592 - val_loss: 0.9355 - val_accuracy: 0.5413\n",
      "Epoch 26/2000\n",
      "1589/1589 [==============================] - 1s 878us/step - loss: 0.9088 - accuracy: 0.5584 - val_loss: 0.9368 - val_accuracy: 0.5430\n",
      "Epoch 27/2000\n",
      "1589/1589 [==============================] - 1s 884us/step - loss: 0.9053 - accuracy: 0.5588 - val_loss: 0.9377 - val_accuracy: 0.5439\n",
      "[21:35:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.097788\n",
      "0:\tlearn: 1.0830973\ttotal: 63.4ms\tremaining: 1m 3s\n",
      "50:\tlearn: 0.9750528\ttotal: 3.46s\tremaining: 1m 4s\n",
      "100:\tlearn: 0.9547095\ttotal: 6.44s\tremaining: 57.3s\n",
      "150:\tlearn: 0.9383412\ttotal: 8.82s\tremaining: 49.6s\n",
      "200:\tlearn: 0.9235374\ttotal: 11.1s\tremaining: 44.1s\n",
      "250:\tlearn: 0.9106865\ttotal: 13.5s\tremaining: 40.4s\n",
      "300:\tlearn: 0.8988446\ttotal: 16.3s\tremaining: 37.9s\n",
      "350:\tlearn: 0.8880347\ttotal: 18.8s\tremaining: 34.8s\n",
      "400:\tlearn: 0.8778365\ttotal: 21.1s\tremaining: 31.5s\n",
      "450:\tlearn: 0.8679770\ttotal: 23.3s\tremaining: 28.3s\n",
      "500:\tlearn: 0.8584481\ttotal: 25.7s\tremaining: 25.6s\n",
      "550:\tlearn: 0.8491467\ttotal: 27.8s\tremaining: 22.7s\n",
      "600:\tlearn: 0.8397668\ttotal: 30.5s\tremaining: 20.2s\n",
      "650:\tlearn: 0.8313563\ttotal: 33.3s\tremaining: 17.8s\n",
      "700:\tlearn: 0.8229100\ttotal: 36s\tremaining: 15.4s\n",
      "750:\tlearn: 0.8145696\ttotal: 38.2s\tremaining: 12.7s\n",
      "800:\tlearn: 0.8065973\ttotal: 40.5s\tremaining: 10.1s\n",
      "850:\tlearn: 0.7986292\ttotal: 42.7s\tremaining: 7.48s\n",
      "900:\tlearn: 0.7907844\ttotal: 45.1s\tremaining: 4.96s\n",
      "950:\tlearn: 0.7827030\ttotal: 47.7s\tremaining: 2.46s\n",
      "999:\tlearn: 0.7754117\ttotal: 50.2s\tremaining: 0us\n",
      "Epoch 1/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 1.0298 - accuracy: 0.4704 - val_loss: 0.9819 - val_accuracy: 0.5120\n",
      "Epoch 2/2000\n",
      "1589/1589 [==============================] - 1s 871us/step - loss: 0.9890 - accuracy: 0.5073 - val_loss: 0.9772 - val_accuracy: 0.5190\n",
      "Epoch 3/2000\n",
      "1589/1589 [==============================] - 1s 877us/step - loss: 0.9769 - accuracy: 0.5149 - val_loss: 0.9590 - val_accuracy: 0.5318\n",
      "Epoch 4/2000\n",
      "1589/1589 [==============================] - 1s 943us/step - loss: 0.9727 - accuracy: 0.5188 - val_loss: 0.9540 - val_accuracy: 0.5333\n",
      "Epoch 5/2000\n",
      "1589/1589 [==============================] - 1s 934us/step - loss: 0.9640 - accuracy: 0.5249 - val_loss: 0.9518 - val_accuracy: 0.5352\n",
      "Epoch 6/2000\n",
      "1589/1589 [==============================] - 1s 887us/step - loss: 0.9541 - accuracy: 0.5306 - val_loss: 0.9461 - val_accuracy: 0.5350\n",
      "Epoch 7/2000\n",
      "1589/1589 [==============================] - 2s 986us/step - loss: 0.9511 - accuracy: 0.5352 - val_loss: 0.9417 - val_accuracy: 0.5369\n",
      "Epoch 8/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9479 - accuracy: 0.5346 - val_loss: 0.9430 - val_accuracy: 0.5385\n",
      "Epoch 9/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9403 - accuracy: 0.5389 - val_loss: 0.9481 - val_accuracy: 0.5352\n",
      "Epoch 10/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9421 - accuracy: 0.5385 - val_loss: 0.9348 - val_accuracy: 0.5385\n",
      "Epoch 11/2000\n",
      "1589/1589 [==============================] - 2s 991us/step - loss: 0.9377 - accuracy: 0.5410 - val_loss: 0.9398 - val_accuracy: 0.5404\n",
      "Epoch 12/2000\n",
      "1589/1589 [==============================] - 1s 900us/step - loss: 0.9374 - accuracy: 0.5417 - val_loss: 0.9348 - val_accuracy: 0.5419\n",
      "Epoch 13/2000\n",
      "1589/1589 [==============================] - 1s 886us/step - loss: 0.9343 - accuracy: 0.5417 - val_loss: 0.9374 - val_accuracy: 0.5394\n",
      "Epoch 14/2000\n",
      "1589/1589 [==============================] - 1s 898us/step - loss: 0.9300 - accuracy: 0.5477 - val_loss: 0.9373 - val_accuracy: 0.5408\n",
      "Epoch 15/2000\n",
      "1589/1589 [==============================] - 2s 945us/step - loss: 0.9302 - accuracy: 0.5461 - val_loss: 0.9328 - val_accuracy: 0.5422\n",
      "Epoch 16/2000\n",
      "1589/1589 [==============================] - 2s 949us/step - loss: 0.9265 - accuracy: 0.5471 - val_loss: 0.9316 - val_accuracy: 0.5463\n",
      "Epoch 17/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9279 - accuracy: 0.5473 - val_loss: 0.9371 - val_accuracy: 0.5378\n",
      "Epoch 18/2000\n",
      "1589/1589 [==============================] - 2s 998us/step - loss: 0.9173 - accuracy: 0.5505 - val_loss: 0.9319 - val_accuracy: 0.5409\n",
      "Epoch 19/2000\n",
      "1589/1589 [==============================] - 2s 978us/step - loss: 0.9202 - accuracy: 0.5516 - val_loss: 0.9338 - val_accuracy: 0.5420\n",
      "Epoch 20/2000\n",
      "1589/1589 [==============================] - 2s 950us/step - loss: 0.9195 - accuracy: 0.5522 - val_loss: 0.9432 - val_accuracy: 0.5356\n",
      "Epoch 21/2000\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.9169 - accuracy: 0.5508 - val_loss: 0.9324 - val_accuracy: 0.5430\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "for i, data in enumerate(blender_datasets, start=3):\n",
    "    X = data.drop('cluster', axis=1).copy()[:len(blender_datasets[-1])]\n",
    "    y = data['cluster'].copy()[:len(blender_datasets[-1])]\n",
    "    model = voting_clf.fit(X, y)\n",
    "    results = model.predict(X)\n",
    "    results_df['classifier_'+str(i)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_0</th>\n",
       "      <th>classifier_1</th>\n",
       "      <th>classifier_2</th>\n",
       "      <th>classifier_3</th>\n",
       "      <th>classifier_4</th>\n",
       "      <th>classifier_5</th>\n",
       "      <th>classifier_6</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63555</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63556</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63557</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63558</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63559</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63560 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       classifier_0  classifier_1  classifier_2  classifier_3  classifier_4  \\\n",
       "0                 2             2             2             2             2   \n",
       "1                 1             2             2             2             2   \n",
       "2                 2             2             2             2             2   \n",
       "3                 2             2             2             2             2   \n",
       "4                 0             0             0             0             0   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "63555             1             2             2             2             1   \n",
       "63556             0             2             1             0             2   \n",
       "63557             0             0             0             0             1   \n",
       "63558             2             0             2             1             1   \n",
       "63559             0             2             2             2             1   \n",
       "\n",
       "       classifier_5  classifier_6  y  \n",
       "0                 2             2  2  \n",
       "1                 2             2  0  \n",
       "2                 2             2  2  \n",
       "3                 2             2  1  \n",
       "4                 0             0  0  \n",
       "...             ...           ... ..  \n",
       "63555             1             1  1  \n",
       "63556             2             2  1  \n",
       "63557             1             1  0  \n",
       "63558             1             1  0  \n",
       "63559             1             1  0  \n",
       "\n",
       "[63560 rows x 8 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['y'] = blender_datasets[-1]['cluster']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_blender, X_test_blender, y_train_blender, y_test_blender = train_test_split(results_df.drop(['y'], axis=1), results_df['y'], stratify=results_df['y'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_model = CatBoostClassifier(iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.096364\n",
      "0:\tlearn: 1.0521566\ttotal: 27.4ms\tremaining: 27.4s\n",
      "50:\tlearn: 0.8606919\ttotal: 2.52s\tremaining: 46.8s\n",
      "100:\tlearn: 0.8586841\ttotal: 5.12s\tremaining: 45.6s\n",
      "150:\tlearn: 0.8559494\ttotal: 8.13s\tremaining: 45.7s\n",
      "200:\tlearn: 0.8530115\ttotal: 11.2s\tremaining: 44.4s\n",
      "250:\tlearn: 0.8497491\ttotal: 14.3s\tremaining: 42.8s\n",
      "300:\tlearn: 0.8470302\ttotal: 17.5s\tremaining: 40.7s\n",
      "350:\tlearn: 0.8436847\ttotal: 20.7s\tremaining: 38.3s\n",
      "400:\tlearn: 0.8401391\ttotal: 23.9s\tremaining: 35.7s\n",
      "450:\tlearn: 0.8368760\ttotal: 27s\tremaining: 32.8s\n",
      "500:\tlearn: 0.8339702\ttotal: 30.2s\tremaining: 30.1s\n",
      "550:\tlearn: 0.8308978\ttotal: 33.4s\tremaining: 27.2s\n",
      "600:\tlearn: 0.8277646\ttotal: 37s\tremaining: 24.6s\n",
      "650:\tlearn: 0.8248894\ttotal: 40.6s\tremaining: 21.8s\n",
      "700:\tlearn: 0.8220199\ttotal: 43.8s\tremaining: 18.7s\n",
      "750:\tlearn: 0.8191028\ttotal: 47.4s\tremaining: 15.7s\n",
      "800:\tlearn: 0.8163312\ttotal: 51.3s\tremaining: 12.7s\n",
      "850:\tlearn: 0.8134683\ttotal: 54.8s\tremaining: 9.6s\n",
      "900:\tlearn: 0.8106840\ttotal: 58.3s\tremaining: 6.4s\n",
      "950:\tlearn: 0.8078359\ttotal: 1m 1s\tremaining: 3.18s\n",
      "999:\tlearn: 0.8053626\ttotal: 1m 5s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2550cbdca00>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender_model.fit(X_train_blender, y_train_blender, cat_features=X_train_blender.columns[:-1], verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2550e8311c0>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(blender_model,\n",
    "                     X_test_blender,\n",
    "                     y_test_blender,\n",
    "                     values_format='d',\n",
    "                     display_labels=['SELL', 'IGNORE', 'BUY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      5515\n",
      "           1       0.61      0.57      0.59      4837\n",
      "           2       0.67      0.73      0.70      5538\n",
      "\n",
      "    accuracy                           0.66     15890\n",
      "   macro avg       0.66      0.66      0.66     15890\n",
      "weighted avg       0.66      0.66      0.66     15890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_blender, blender_model.predict(X_test_blender)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
